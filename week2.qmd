# 第二周：数据预处理与特征工程基础

## 第二次课：数据预处理与特征工程基础

### 课程目标

*   掌握使用 `Pandas` 进行数据加载和探索的方法，包括数据读取、查看、统计分析和可视化。
*   掌握常见的数据清洗方法，包括缺失值处理 (删除、填充) 和异常值处理 (检测与处理)。
*   理解特征工程的基本概念和方法，包括数值特征处理 (特征缩放、特征转换) 和类别特征处理 (独热编码、标签编码)。
*   掌握使用 `Scikit-learn` 进行数据预处理和特征工程的常用方法。
*   能够使用 AI 辅助编程工具完成数据预处理和特征工程的编程练习。
*   了解小组项目一：电商用户行为数据探索与预处理 的目标、数据集和任务要求。

### 内容概要

1.  **数据加载与探索**
    *   **使用 `Pandas` 读取数据:**
        *   `pd.read_csv()`, `pd.read_excel()` 等常用数据读取函数。
        *   常用参数：`filepath_or_buffer`, `sep`, `header`, `index_col`, `encoding` 等。
    *   **数据查看:**
        *   `df.head()`, `df.tail()`, `df.sample()`:  查看数据的前几行、后几行或随机抽样行。
        *   `df.info()`:  查看数据类型、缺失值情况、内存占用等信息。
        *   `df.describe()`:  查看数值特征的统计描述 (均值、标准差、最小值、最大值、分位数等)。
        *   `df.shape`, `df.columns`, `df.index`, `df.dtypes`:  查看数据维度、列名、索引和数据类型。
    *   **数据基本统计分析:**
        *   数值特征统计：`df['列名'].mean()`, `df['列名'].median()`, `df['列名'].std()`, `df['列名'].max()`, `df['列名'].min()`, `df['列名'].value_counts()` 等。
        *   类别特征统计：`df['列名'].value_counts()`, `df['列名'].unique()`, `df['列名'].nunique()` 等。
        *   相关性分析：`df.corr()` (计算特征之间的相关系数)。
    *   **数据可视化 (初步):**
        *   直方图：`df['列名'].hist()` (查看数值特征分布)。
        *   箱线图：`df.boxplot(column=['列名'])` (查看数值特征的箱线图，检测异常值)。
        *   散点图：`df.plot.scatter(x='列名1', y='列名2')` (查看两个数值特征之间的关系)。
        *   柱状图：`df['列名'].value_counts().plot.bar()` (查看类别特征的分布)。
        *   **使用 `matplotlib` 和 `seaborn` 进行更高级的数据可视化 (下周详细讲解)。**

2.  **数据清洗**
    *   **缺失值处理:**
        *   **检测缺失值:**  `df.isnull()`, `df.sum()`, `df.isnull().sum()`, `missingno` 库 (可视化缺失值)。
        *   **缺失值处理策略:**
            *   **删除法:**  `df.dropna()` (删除包含缺失值的行或列，慎用，可能丢失信息)。
            *   **填充法:**  `df.fillna(value)`, `df['列名'].fillna(value)` (使用固定值、均值、中位数、众数等填充缺失值)。
            *   **插值法:**  `df.interpolate()` (使用插值方法估计缺失值，例如线性插值、多项式插值等)。
            *   **高级方法:**  使用模型预测缺失值 (例如 KNN 填充、回归填充等，本课程不深入讲解)。

        ::: callout-note
        ## 选择合适的缺失值处理策略
        需要根据具体情况和业务理解。
        :::

    *   **异常值处理:**
        *   **异常值检测方法:**
            *   **箱线图 (Boxplot):**  箱线图以外的点通常被认为是异常值。
            *   **Z-score:**  计算 Z-score，绝对值大于阈值 (例如 3) 的被认为是异常值。
            *   **IQR (四分位距):**  超出 Q1 - 1.5IQR 或 Q3 + 1.5IQR 范围的值被认为是异常值。
            *   **其他方法:**  聚类、LOF (局部离群因子) 等算法 (本课程不深入讲解)。
        *   **异常值处理策略:**
            *   **删除法:**  直接删除异常值 (慎用，可能丢失信息)。
            *   **替换法:**  使用均值、中位数、边界值等替换异常值。
            *   **视为缺失值:**  将异常值替换为缺失值，再进行缺失值处理。
            *   **不处理:**  有些情况下，异常值可能包含有价值的信息，可以考虑不处理。

        ::: callout-note
        ## 异常值处理
        同样需要根据具体情况和业务理解。
        :::

3.  **特征工程基础**
    *   **数值特征处理:**
        *   **特征缩放 (Feature Scaling):**  将数值特征缩放到一定范围，避免特征量纲不一致和数值过大/过小带来的问题。
            *   **标准化 (Standardization):**  将特征缩放到均值为 0，标准差为 1 的分布 (也称 Z-score 归一化)。
                *   公式：`x_scaled = (x - mean) / std`
                *   `sklearn.preprocessing.StandardScaler`
            *   **归一化 (Normalization):**  将特征缩放到 0 和 1 之间 (也称 Min-Max 缩放)。
                *   公式：`x_scaled = (x - min) / (max - min)`
                *   `sklearn.preprocessing.MinMaxScaler`
            *   **其他缩放方法:**  `RobustScaler` (基于四分位距缩放，对异常值更鲁棒), `MaxAbsScaler` (绝对值最大值缩放) 等。

        ::: callout-note
        ## 选择合适的缩放方法
        需要根据数据分布和模型特点。
        :::

        *   **特征转换 (Feature Transformation):**  对数值特征进行函数变换，使其更符合模型假设或业务需求。
            *   **多项式特征:**  将特征进行多项式扩展，增加特征的非线性性。
                *   例如：将特征 `x` 转换为 `x`, `x^2`, `x^3` 等。
                *   `sklearn.preprocessing.PolynomialFeatures`
            *   **对数变换:**  对特征取对数，减小数值范围，平滑数据分布，处理长尾分布。
                *   例如：`log(x + 1)` (加 1 是为了避免对 0 取对数)。
                *   `numpy.log1p`, `sklearn.preprocessing.PowerTransformer`
            *   **指数变换:**  对特征取指数。
            *   **Box-Cox 变换, Yeo-Johnson 变换:**  更通用的幂变换，可以处理不同分布的数据。
                *   `sklearn.preprocessing.PowerTransformer`

        ::: callout-note
        ## 选择合适的特征转换方法
        根据业务理解和数据探索选择。
        :::

    *   **类别特征处理:**
        *   **独热编码 (One-Hot Encoding):**  将类别特征转换为多个二元特征，每个类别对应一列，存在该类别则为 1，否则为 0。
            *   适用于类别之间没有顺序关系的情况 (例如：颜色、城市)。
            *   `pandas.get_dummies`, `sklearn.preprocessing.OneHotEncoder`

        ::: callout-warning
        ## 注意
        处理高基数类别特征 (类别数量过多) 可能导致维度灾难。
        :::

        *   **标签编码 (Label Encoding):**  将类别特征转换为数值标签，每个类别对应一个整数。
            *   适用于类别之间有顺序关系的情况 (例如：学历、等级)。
            *   `sklearn.preprocessing.LabelEncoder`

        ::: callout-warning
        ## 注意
        标签编码可能会引入类别之间的顺序关系，如果类别没有实际顺序意义，可能不适用。
        :::

        *   **顺序编码 (Ordinal Encoding):**  类似于标签编码，但可以自定义类别顺序。
            *   适用于类别之间有明确顺序关系的情况。
            *   `sklearn.preprocessing.OrdinalEncoder`
        *   **二进制编码 (Binary Encoding), 效应编码 (Effect Encoding), 目标编码 (Target Encoding) 等其他类别特征编码方法 (本课程不深入讲解)。**

        ::: callout-note
        ## 选择合适的类别特征编码方法
        需要根据数据特点和模型需求。
        :::

4.  **`Scikit-learn` 数据预处理和特征工程常用模块**
    *   `sklearn.preprocessing`:  提供了各种数据预处理和特征工程的函数和类，例如：
        *   `StandardScaler`, `MinMaxScaler`, `RobustScaler`, `MaxAbsScaler` (特征缩放)。
        *   `PolynomialFeatures`, `PowerTransformer` (特征转换)。
        *   `OneHotEncoder`, `LabelEncoder`, `OrdinalEncoder` (类别特征编码)。
        *   `SimpleImputer` (缺失值填充)。
    *   `sklearn.impute`:  提供了缺失值填充的类，例如 `SimpleImputer`, `KNNImputer` (KNN 填充), `IterativeImputer` (迭代填充)。
    *   `sklearn.feature_selection`:  提供了特征选择的类 (下周讲解)。

        ::: callout-note
        ## 熟练使用 Scikit-learn
        可以高效地进行数据预处理和特征工程。
        :::

5.  **小组项目一：电商用户行为数据探索与预处理 (案例介绍与数据准备)**
    *   **项目背景:**  电商平台积累了大量的用户行为数据，例如用户的点击、浏览、购买、加购、收藏等行为。  通过分析这些数据，可以了解用户兴趣偏好、购买行为模式，为个性化推荐、精准营销、用户增长等提供数据支持。
    *   **数据集:**  **鼓励学生小组自主选择数据集**，建议选择电商或零售行业的用户行为数据集。 数据集应包含用户行为数据，数据量适中，特征维度不低于10个，且具有一定的分类难度。 **鼓励各小组选择不同的数据集，以提高项目实践的多样性。**  **(本课程提供 [阿里巴巴天池 - 淘宝用户行为数据](https://tianchi.aliyun.com/dataset/dataDetail?dataId=649)  作为示例数据集)**。
        *   **(示例数据集) 阿里巴巴天池 - 淘宝用户行为数据:**  数据集包含 2000 万条淘宝用户的行为记录，字段包括：用户ID、商品ID、商品类目ID、行为类型 (点击、浏览、加购、购买)、时间戳。
        *   **数据已进行简化处理，只保留了部分用户和商品数据，并转换为 CSV 格式，方便教学使用。**
    *   **项目目标:**  对电商用户行为数据进行探索性数据分析 (EDA) 和预处理，为后续的机器学习建模 (例如用户行为预测、商品推荐) 做好数据准备。
    *   **项目任务 (小组完成):**
        *   **数据探索:**
            *   加载数据集，查看数据基本信息 (数据类型、缺失值等)。
            *   分析用户行为类型分布、时间分布、用户和商品数量等。
            *   可视化用户行为数据，例如用户行为时间序列图、商品销量排行榜等。
        *   **数据清洗:**
            *   处理缺失值 (如果存在)。
            *   检测和处理异常值 (例如时间戳异常)。
            *   **根据数据探索结果，进行必要的数据清洗操作。**
        *   **特征工程:**
            *   **基于用户行为数据，构建用户特征和商品特征。**  (例如：用户点击次数、购买次数、浏览商品类目数；商品被点击次数、被购买次数等)。
            *   **可以尝试构建一些交叉特征或衍生特征。**
            *   **对特征进行必要的预处理 (例如特征缩放、类别编码)。**
        *   **提交内容:**
            *   **预处理后的数据集 (CSV 格式)。**
            *   **Python 代码 (Jupyter Notebook 或 Python 脚本)，包含数据探索、清洗和特征工程的完整代码，代码需要有清晰的注释。**
            *   **小组分工说明 (可选)。**
    *   **评分标准:**  数据预处理的完整性、代码的规范性、数据探索的深入程度、特征工程的合理性。
    *   **下周第二次课进行小组项目展示和代码讲解。**

### 实践环节

1.  **数据加载与探索练习:**  使用 `Pandas` 读取 CSV 数据集 (提供示例数据集)，进行数据查看、统计分析和可视化练习。
2.  **数据清洗练习:**  对示例数据集进行缺失值和异常值处理练习，尝试不同的处理策略，并比较效果。
3.  **特征工程基础练习:**  对示例数据集进行数值特征缩放、特征转换和类别特征编码练习，使用 `Scikit-learn` 提供的工具。
4.  **小组项目一：数据探索与预处理实践:**  小组合作，开始进行电商用户行为数据集的数据探索、数据清洗和特征工程，完成数据预处理代码初稿。
5.  **使用 AI 工具辅助完成数据预处理和特征工程代码，提高代码编写效率。**

### 课后作业

1.  **完成数据加载、数据查看、数据基本统计分析和可视化的编程练习，并将代码上传到 GitHub 仓库。**
2.  **完成数据清洗 (缺失值处理、异常值处理) 和特征工程 (数值特征处理、类别特征处理) 的编程练习，并将代码上传到 GitHub 仓库。**
3.  **小组合作完成小组项目一：电商用户行为数据探索与预处理 的数据预处理代码，并提交预处理后的数据集和代码到指定平台 (例如 GitHub 仓库)。**
4.  **预习下周课程内容：特征选择与降维。**
5.  **思考题：**  在数据预处理和特征工程中，如何选择合适的方法和策略？  数据预处理和特征工程对机器学习模型性能的影响？

### 相关资源

*   **`Pandas` 官方文档:**  [pandas.pydata.org/docs/](https://pandas.pydata.org/docs/)
*   **`Scikit-learn` 官方文档:**  [scikit-learn.org/stable/](https://scikit-learn.org/stable/)
*   **`Scikit-learn` Preprocessing 模块文档:**  [scikit-learn.org/stable/modules/preprocessing.html](https://scikit-learn.org/stable/modules/preprocessing.html)
*   **`Scikit-learn` Impute 模块文档:**  [scikit-learn.org/stable/modules/impute.html](https://scikit-learn.org/stable/modules/impute.html)
*   **《Python Data Science Handbook》:**  [jakevdp.github.io/PythonDataScienceHandbook/](https://jakevdp.github.io/PythonDataScienceHandbook/) (Chapter 3, Chapter 4, Chapter 5)
*   **《Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow》:** [www.oreilly.com/library/view/hands-on-machine-learning/9781098125973/](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125973/) (Chapter 2, Chapter 3)
*   **阿里巴巴天池 - 淘宝用户行为数据:**  [https://tianchi.aliyun.com/dataset/dataDetail?dataId=649](https://tianchi.aliyun.com/dataset/dataDetail?dataId=649)

---

## 第三次课：特征选择与降维 (下周内容预告)

### 课程目标 (下周)

*   理解特征选择和降维的目的和意义。
*   掌握常用的特征选择方法，包括过滤式、包裹式和嵌入式方法。
*   掌握常用的降维方法，包括 PCA 和 t-SNE。
*   能够使用 `Scikit-learn` 进行特征选择和降维操作。

### 内容概要 (下周)

1.  **特征选择**
    *   特征选择的目的和意义：降维、去除冗余特征、提高模型性能、可解释性。
    *   特征选择方法：
        *   **过滤式 (Filter methods):**  基于特征与目标变量之间的统计指标进行选择 (例如：方差选择、相关系数、卡方检验、互信息)。
        *   **包裹式 (Wrapper methods):**  将特征子集的选择看作搜索问题，使用模型性能作为评价指标进行选择 (例如：递归特征消除 RFE)。
        *   **嵌入式 (Embedded methods):**  将特征选择融入到模型训练过程中 (例如：L1 正则化、树模型特征重要性)。
    *   `Scikit-learn` 特征选择模块：`sklearn.feature_selection`。

2.  **降维**
    *   降维的目的和意义：降维、可视化、去除噪声、提高计算效率。
    *   常用降维方法：
        *   **主成分分析 (PCA):**  线性降维方法，通过正交变换将数据投影到低维空间，使得投影后的数据方差最大化。
        *   **t-SNE:**  非线性降维方法，用于高维数据可视化，将高维数据映射到低维空间，保持数据点的局部邻域结构。
        *   `Scikit-learn` 降维模块：`sklearn.decomposition` (PCA), `sklearn.manifold` (t-SNE)。

3.  **实践环节 (下周)**
    *   使用 `Scikit-learn` 进行特征选择和降维的编程练习。
    *   结合实际数据集，应用特征选择和降维方法，并评估模型性能。

### 课后作业 (下周)

*   完成特征选择和降维的编程练习，并将代码上传到 GitHub 仓库。
*   查阅资料，深入了解特征选择和降维的原理和应用场景。
*   思考题：特征选择和降维的区别和联系？  如何根据实际问题选择合适的特征选择和降维方法？

### 相关资源 (下周)

*   **`Scikit-learn` Feature Selection 模块文档:**  [scikit-learn.org/stable/modules/feature_selection.html](https://scikit-learn.org/stable/modules/feature_selection.html)
*   **`Scikit-learn` Decomposition 模块文档 (PCA):**  [scikit-learn.org/stable/modules/decomposition.html](https://scikit-learn.org/stable/modules/decomposition.html)
*   **`Scikit-learn` Manifold 模块文档 (t-SNE):**  [scikit-learn.org/stable/modules/manifold.html](https://scikit-learn.org/stable/modules/manifold.html)
*   **《Python Data Science Handbook》:**  [jakevdp.github.io/PythonDataScienceHandbook/](https://jakevdp.github.io/PythonDataScienceHandbook/) (Chapter 5)
*   **《Hands-On Machine Learning with Scikit-Learn, Keras & TensorFlow》:** [www.oreilly.com/library/view/hands-on-machine-learning/9781098125973/](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125973/) (Chapter 7, Chapter 8)

---
