---
title: "第七周：课堂练习与实验"
subtitle: "K-Means 聚类实践与 K 值选择"
---

# 第七周：课堂练习与实验

本周我们进入无监督学习的世界，重点练习 K-Means 聚类算法，学习如何选择合适的簇数量 K，并开始我们的用户分群项目。

## 准备工作

确保导入本周所需的库：

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import make_blobs, make_moons # 导入生成数据的函数
from sklearn.preprocessing import StandardScaler # 导入数据缩放器
from sklearn.cluster import KMeans # 导入KMeans聚类算法
from sklearn.metrics import silhouette_score, davies_bouldin_score # 导入评估指标
from sklearn.decomposition import PCA # 导入PCA
from sklearn.manifold import t_SNE # 导入t-SNE，用于可视化

# 设置 matplotlib 绘图样式 (可选)
plt.style.use('seaborn-v0_8-whitegrid')
# %matplotlib inline # 如果在 Jupyter 环境中需要取消注释
```

## 练习 1: K-Means 基础实践

**目标:** 熟悉 K-Means 算法的基本使用和结果可视化。

1.  **生成数据:**
    *   使用 `make_blobs` 生成包含 4 个簇的二维数据集。设置 `n_samples=400`, `centers=4`, `cluster_std=0.6`, `random_state=0`。将特征赋值给 `X`, 真实标签赋值给 `y_true` (虽然 K-Means 是无监督的，但真实标签有助于我们后续评估 K 值选择的效果)。
    *   绘制散点图观察生成的数据分布。

2.  **数据缩放:**
    *   初始化 `StandardScaler`。
    *   对特征数据 `X` 进行 `fit_transform`，得到 `X_scaled`。

3.  **训练 K-Means:**
    *   创建一个 `KMeans` 实例，设置 `n_clusters=4` (假设我们已知或猜对了簇数), `init='k-means++'`, `n_init='auto'`, `random_state=42`。
    *   使用**缩放后**的数据 `X_scaled` 训练模型 (`fit()` 方法)。

4.  **获取结果:**
    *   获取模型预测的簇标签 `kmeans_labels = kmeans.labels_`。
    *   获取簇中心点坐标 `centroids = kmeans.cluster_centers_`。

5.  **可视化结果:**
    *   绘制散点图，使用 `X_scaled` 作为坐标，并根据 `kmeans_labels` 对点进行着色 (`c=kmeans_labels`, `cmap='viridis'`)。
    *   在同一图上，用不同的标记（例如红色 'X'）绘制簇中心点 `centroids`。
    *   添加标题和坐标轴标签。
    *   调用 `plt.show()`。

## 练习 2: 选择最佳 K 值

**目标:** 应用肘部法则和轮廓系数来为 K-Means 选择合适的 K 值。

**继续使用练习 1 中的 `X_scaled` 数据。**

1.  **肘部法则 (Elbow Method):**
    *   创建一个空列表 `inertia_list` 用于存储 inertia 值。
    *   设置一个 K 值的范围，例如 `k_range = range(1, 11)`。
    *   使用 `for` 循环遍历 `k_range`：
        *   在循环内，创建 `KMeans` 实例，设置 `n_clusters=k`, `init='k-means++'`, `n_init='auto'`, `random_state=42`。
        *   用 `X_scaled` 训练模型。
        *   将模型的 `inertia_` 属性值添加到 `inertia_list` 中。
    *   绘制 K 值 (`k_range`) 与 Inertia (`inertia_list`) 的关系图。
    *   添加标题 ("Elbow Method for Optimal K")、坐标轴标签 ("Number of Clusters (K)", "Inertia") 和网格线。
    *   调用 `plt.show()`。
    *   **分析:** 在 Markdown 单元格中指出你观察到的“肘部”大约在哪个 K 值。

2.  **轮廓系数 (Silhouette Score):**
    *   创建一个空列表 `silhouette_list`。
    *   设置 K 值的范围，从 2 开始，例如 `k_range_sil = range(2, 11)`。
    *   使用 `for` 循环遍历 `k_range_sil`：
        *   创建 `KMeans` 实例，设置 `n_clusters=k`, `init='k-means++'`, `n_init='auto'`, `random_state=42`。
        *   训练模型并获取预测标签 `labels = kmeans.fit_predict(X_scaled)`。
        *   使用 `silhouette_score(X_scaled, labels)` 计算该 K 值对应的平均轮廓系数，并添加到 `silhouette_list`。
    *   绘制 K 值 (`k_range_sil`) 与轮廓系数 (`silhouette_list`) 的关系图。
    *   添加标题 ("Silhouette Score for Optimal K")、坐标轴标签 ("Number of Clusters (K)", "Average Silhouette Score") 和网格线。
    *   调用 `plt.show()`。
    *   **分析:** 在 Markdown 单元格中指出哪个 K 值对应的轮廓系数最高。

3.  **确定 K:** 结合肘部法则和轮廓系数的结果，以及我们生成数据时已知的真实簇数 (4)，在 Markdown 单元格中讨论并确定最合适的 K 值。

## 练习 3: 聚类评估与可视化 (使用选定的 K)

**目标:** 使用选定的 K 值进行最终聚类，并评估和可视化结果。

1.  **最终聚类:**
    *   使用练习 2 中确定的最佳 K 值（应该是 4）重新创建一个 `KMeans` 实例。
    *   用 `X_scaled` 训练模型并获取最终的聚类标签 `final_labels`。

2.  **评估:**
    *   计算并打印最终聚类的**轮廓系数** (`silhouette_score`)。
    *   计算并打印最终聚类的**戴维斯-布尔丁指数** (`davies_bouldin_score`)。

3.  **可视化 (PCA):**
    *   创建一个 `PCA` 实例，设置 `n_components=2`, `random_state=42`。
    *   对 `X_scaled` 进行 `fit_transform` 得到 `X_pca`。
    *   绘制散点图，x 轴为 PCA 第一个主成分，y 轴为第二个主成分，用 `final_labels` 进行着色。
    *   添加标题和坐标轴标签。
    *   调用 `plt.show()`。

4.  **(可选) 可视化 (t-SNE):**
    *   创建一个 `t_SNE` 实例，设置 `n_components=2`, `perplexity=30` (或其他合适的值), `random_state=42`。
    *   对 `X_scaled` 进行 `fit_transform` 得到 `X_tsne`。
    *   绘制散点图，x 轴为 t-SNE 第一个维度，y 轴为第二个维度，用 `final_labels` 进行着色。
    *   添加标题和坐标轴标签。
    *   调用 `plt.show()`。
    *   在 Markdown 单元格中比较 PCA 和 t-SNE 的可视化效果。

## 练习 4: 项目三 - 阶段一 (K-Means & K 选择)

**目标:** 将 K-Means 应用于你的用户分群项目数据。

1.  **加载与预处理:**
    *   加载你的项目三数据集。
    *   选择用于聚类的相关特征（通常是用户的行为或属性数据，如购买频率、消费金额、访问时长、年龄等）。
    *   进行必要的预处理：处理缺失值、对类别特征进行编码（如果需要）。
    *   **对所有选定的数值特征进行标准化 (`StandardScaler`)**。将处理后的数据存为 `X_project_scaled`。

2.  **选择 K 值:**
    *   应用**肘部法则**：计算不同 K 值 (例如 1 到 15 或 20) 对应的 Inertia，并绘制肘部图。
    *   应用**轮廓系数法**：计算不同 K 值 (例如 2 到 15 或 20) 对应的平均轮廓系数，并绘制轮廓系数图。
    *   **分析:** 在 Markdown 单元格中结合两个图表，以及你对业务的理解（你期望用户大致可以分为几类？），选择一个或几个最可能的 K 值。

3.  **执行聚类:**
    *   使用你选择的最佳 K 值，创建并训练 `KMeans` 模型。
    *   获取聚类标签。

4.  **初步可视化 (如果特征维度 > 2):**
    *   使用 PCA 或 t-SNE 将你的 `X_project_scaled` 数据降维到 2 维。
    *   绘制降维后的散点图，并根据聚类标签着色。
    *   观察聚类效果。

**将以上步骤的代码、图表和分析记录在你的项目三 Notebook 中。这是项目三第一阶段的核心内容。**