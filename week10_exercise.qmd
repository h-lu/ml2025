---
title: "第十周：课堂练习与实验"
subtitle: "降维与特征选择"
format:
  html:
    toc: true
    toc-location: left
    code-fold: show
    theme: cosmo
---

# 第十周：课堂练习与实验

本周我们学习处理高维数据的两种主要方法：降维（以 PCA 为主）和特征选择。这些技术有助于简化模型、提高效率并可能改善性能。

## 准备工作

确保导入本周所需的库：

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_digits # 一个多维数据集示例
from sklearn.model_selection import train_test_split, cross_val_score
from sklearn.preprocessing import StandardScaler
from sklearn.decomposition import PCA
from sklearn.feature_selection import VarianceThreshold, SelectKBest, f_classif, RFE
from sklearn.linear_model import LogisticRegression, Lasso
from sklearn.ensemble import RandomForestClassifier
from sklearn.feature_selection import SelectFromModel
from sklearn.metrics import accuracy_score

# 设置 matplotlib 绘图样式 (可选)
plt.style.use('seaborn-v0_8-whitegrid')
# %matplotlib inline # 取消注释以便在 Jupyter 环境中显示绘图

# --- 加载数据 ---
digits = load_digits()
X, y = digits.data, digits.target
# 获取特征名称（这里用数字索引代替，因为原始特征是像素点）
feature_names = [f'pixel_{i}' for i in range(X.shape[1])]
print("原始数据形状:", X.shape) # (1797, 64)

# --- 数据预处理和划分 ---
# 特征缩放对于 PCA 和 RFE(带正则化模型) 很重要
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)

X_train, X_test, y_train, y_test = train_test_split(
    X_scaled, y, test_size=0.3, random_state=42, stratify=y
)
# 使用未缩放的数据进行方差阈值和相关性分析
X_train_orig, X_test_orig, _, _ = train_test_split(
    X, y, test_size=0.3, random_state=42, stratify=y
)


print("训练集形状:", X_train.shape) # (~1257, 64)
print("测试集形状:", X_test.shape)   # (~540, 64)

# 为了方便比较，先训练一个基准模型（在所有特征上）
print("\n训练基准 Logistic Regression 模型...")
base_model_lr = LogisticRegression(max_iter=2000, random_state=42) # Increased max_iter for convergence
base_model_lr.fit(X_train, y_train)
base_accuracy_lr = base_model_lr.score(X_test, y_test)
print(f"基准 Logistic Regression (所有特征) 测试集准确率: {base_accuracy_lr:.4f}")

# 训练一个随机森林模型，后面练习会用到
print("\n训练基准 RandomForest 模型...")
rf_model_full = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)
rf_model_full.fit(X_train, y_train)
rf_accuracy_full = rf_model_full.score(X_test, y_test)
print(f"基准 RandomForest 模型 (所有特征) 测试集准确率: {rf_accuracy_full:.4f}")
```

## 练习 1: 主成分分析 (PCA) 实践

**目标:** 应用 PCA 进行降维，并理解方差解释率。

1.  **计算并可视化累积方差解释率:**
    *   创建一个 `PCA` 实例 (`pca_full`)，不指定 `n_components`。
    *   使用 `fit()` 方法拟合**缩放后的训练数据** `X_train`。
    *   计算累积方差解释率 `explained_variance_ratio_cumsum = np.cumsum(pca_full.explained_variance_ratio_)`。
    *   绘制累积方差解释率曲线图，x 轴是主成分数量 (从 1 到 64)，y 轴是累积方差解释率。
    *   在图上添加一条水平线表示 95% 的方差阈值 (`plt.axhline(0.95, color='r', linestyle='--', label='95% Variance')`)。
    *   添加标题 ("Explained Variance by Number of Components") 和坐标轴标签 ("Number of Components", "Cumulative Explained Variance Ratio")。
    *   添加图例 (`plt.legend()`)。
    *   调用 `plt.show()`。
    *   **分析:** 在 Markdown 单元格中回答：大约需要多少个主成分才能保留 95% 的原始数据方差？

2.  **应用 PCA 进行降维 (保留 95% 方差):**
    *   创建一个新的 `PCA` 实例 (`pca_95`)，设置 `n_components=0.95`。
    *   使用 `fit_transform()` 对 `X_train` 进行降维，得到 `X_train_pca95`。
    *   使用**同一个** `pca_95` 实例对 `X_test` 进行 `transform`，得到 `X_test_pca95`。
    *   打印降维后训练集和测试集的形状。

3.  **评估降维后模型的性能:**
    *   创建一个新的 `LogisticRegression` 实例 (`lr_pca95`, `max_iter=1000`, `random_state=42`)。
    *   在降维后的训练数据 `X_train_pca95` 上训练模型。
    *   在降维后的测试数据 `X_test_pca95` 上评估模型准确率。
    *   **比较:** 在 Markdown 单元格中比较使用 PCA (95% 方差) 后的模型准确率与基准模型（使用所有 64 个特征）的准确率。性能是否有显著下降？计算量是否减少了（体现在特征数量上）？

4.  **可视化 2D 降维结果:**
    *   创建一个 `PCA` 实例 (`pca_2d`)，设置 `n_components=2`, `random_state=42`。
    *   对 `X_train` 进行 `fit_transform` 得到 `X_train_pca_2d`。
    *   绘制散点图，x 轴为第一个主成分，y 轴为第二个主成分，用 `y_train` 对点进行着色 (`c=y_train`, `cmap='viridis'`)。
    *   添加标题 ("PCA of Digits Dataset (2 Components)")、坐标轴标签 ("Principal Component 1", "Principal Component 2") 和颜色条 (`plt.colorbar(label='Digit Label')`)。
    *   调用 `plt.show()`。
    *   **思考:** 在 Markdown 单元格中讨论：从二维可视化中，你能看出不同数字类别的大致分布或可分性吗？PCA 是否能很好地分离所有类别？

## 练习 2: 过滤法 (Filter Methods) 特征选择

**目标:** 应用方差阈值和单变量选择方法。

**继续使用 `X_train`, `y_train`, `X_test` (注意：过滤法通常在缩放前应用效果更明显，但为方便比较，这里也可用缩放后数据，但要理解其影响)。**

1.  **方差阈值 (Variance Threshold):**
    *   **思考:** 对原始数据 `digits.data` (未缩放) 应用方差阈值是否有意义？为什么？（在 Markdown 单元格回答）
    *   创建一个 `VarianceThreshold` 实例 (`selector_var`)。
    *   使用 `fit()` 拟合**原始未缩放**的训练数据 `X_train_orig`。
    *   打印保留的特征数量 (`selector_var.get_support().sum()`)。
    *   **注意:** 默认阈值为 0，即只移除方差为 0 的特征（常量特征）。可以尝试设置不同的 `threshold` 值（如 0.1, 1.0）观察效果。

2.  **单变量选择 (SelectKBest):**
    *   创建一个 `SelectKBest` 实例 (`selector_kbest`)。
    *   设置 `score_func=f_classif` (因为是分类问题)。
    *   设置 `k=20` (选择最重要的 20 个特征)。
    *   使用 `fit_transform()` 应用于 `X_train` 和 `y_train`，得到 `X_train_kbest`。
    *   使用**同一个** `SelectKBest` 实例对 `X_test` 进行 `transform`，得到 `X_test_kbest`。
    *   打印筛选后的特征数量。
    *   获取被选中的特征的索引: `selected_indices_kbest = selector_kbest.get_support(indices=True)`。
    *   (可选) 获取原始特征名称 `np.array(feature_names)[selected_indices_kbest]`。
    *   **评估性能:** 训练一个 `LogisticRegression` 模型 (`max_iter=1000`, `random_state=42`) 在 `X_train_kbest` 上，然后在 `X_test_kbest` 上评估准确率。与基准模型 `base_model_lr` 比较。

## 练习 3: 包裹法 (Wrapper Method) - RFE

**目标:** 应用递归特征消除 (RFE) 进行特征选择。

**继续使用 `X_train_scaled`, `y_train`, `X_test_scaled` (RFE 对特征缩放不敏感，但如果使用正则化模型作为 estimator 则需要缩放)。**

1.  **创建 RFE 实例:**
    *   选择一个能提供特征重要性或系数的基模型。这里我们用 `RandomForestClassifier(n_estimators=50, random_state=42, n_jobs=-1)` 作为 `estimator`。
    *   创建一个 `RFE` 实例 (`selector_rfe`)。
    *   设置 `estimator`。
    *   设置 `n_features_to_select=32` (选择大约一半的特征)。
    *   设置 `step=1` (每次迭代移除一个特征)。
2.  **执行 RFE:**
    *   使用 `fit()` 方法在 `X_train_scaled` 和 `y_train` 上训练 RFE 选择器。**这可能需要一些时间。**
3.  **查看结果:**
    *   打印 `selector_rfe.support_` 查看哪些特征被选中 (True/False 数组)。
    *   打印 `selector_rfe.ranking_` 查看特征的排名 (1 表示最重要)。
    *   获取被选中的特征的索引: `selected_indices_rfe = selector_rfe.get_support(indices=True)`。
4.  **转换数据:**
    *   使用 `transform()` 方法转换 `X_train_scaled` 和 `X_test_scaled`，得到 `X_train_rfe` 和 `X_test_rfe`。
    *   打印转换后训练集的形状。
5.  **评估性能:**
    *   训练一个**新的** `RandomForestClassifier` 实例（可以使用与 RFE 相同的参数或 `n_estimators=100`）在 RFE 筛选后的训练集 `X_train_rfe` 上。
    *   在 `X_test_rfe` 上评估性能（准确率）。
    *   与基准模型（使用所有特征的 Logistic Regression `base_model_lr`）和使用所有特征的 RandomForest (准备工作中训练的模型 `rf_model_full`) 进行比较。

## 练习 4: 嵌入法 (Embedded Method) - 基于树的重要性

**目标:** 使用随机森林的特征重要性进行特征选择。

**继续使用 `X_train_scaled`, `y_train`, `X_test_scaled`。**

1.  **获取特征重要性:**
    *   使用准备工作中训练好的 `rf_model_full`。获取其 `feature_importances_`。

2.  **使用 SelectFromModel:**
    *   创建一个 `SelectFromModel` 实例 (`sfm_selector`)。
    *   传入 `rf_model_full` 作为 `estimator`。
    *   设置 `threshold='median'` (选择重要性高于中位数的特征)。你也可以尝试其他阈值，如 `'mean'` 或一个具体的数值 (例如 `0.01`)。
    *   设置 `prefit=True` 因为模型已经训练好了。
    *   **注意:** 如果 `rf_model_full` 未在准备工作中训练，需要先训练或设置 `prefit=False` 并在下一步 fit。
3.  **转换数据:**
    *   使用 `transform()` 方法转换 `X_train_scaled` 和 `X_test_scaled`，得到 `X_train_sfm` 和 `X_test_sfm`。
    *   打印筛选后的特征数量。
    *   获取被选中的特征的索引: `selected_indices_sfm = sfm_selector.get_support(indices=True)`。
4.  **评估性能:**
    *   训练一个新的 `RandomForestClassifier` 实例 (`n_estimators=100`, `random_state=42`) 在 `X_train_sfm` 上。
    *   在 `X_test_sfm` 上评估性能（准确率）。
    *   与基准模型 (`base_model_lr`, `rf_model_full`) 进行比较。

## 练习 5: 讨论与总结

1.  在 Markdown 单元格中，简要比较你在练习 2、3、4 中使用的特征选择方法（SelectKBest、RFE、SelectFromModel）的优缺点和计算成本。哪种方法在你看来效果最好？
2.  PCA 和特征选择都是处理高维数据的方法，它们的主要区别是什么？PCA 保留了多少原始特征？特征选择呢？
3.  在什么情况下你倾向于使用 PCA？什么情况下倾向于使用特征选择？
4.  回顾你之前完成的项目（项目一、二、三），思考在哪些项目中应用降维或特征选择可能会有帮助？为什么？

**通过这些练习，你将更好地理解何时以及如何使用降维和特征选择来处理高维数据。**