<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>第六周：回归算法进阶 - XGBoost 与模型优化 – 机器学习Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week7_lecture.html" rel="next">
<link href="./week5_lecture.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles/custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week6_lecture.html"><span class="chapter-title">第六周：回归算法进阶 - XGBoost 与模型优化</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">机器学习Python</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">index.html</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">讲义</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第一周：机器学习世界初探与工具准备</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第二周：数据处理利器 Numpy &amp; Pandas 与项目启动</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第三周：分类算法初探 - 逻辑回归与支持向量机</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第四周：决策树与随机森林 - 模型优化初探</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第五周：回归算法启程 - 线性回归与多项式回归</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_lecture.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">第六周：回归算法进阶 - XGBoost 与模型优化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第七周：无监督学习初探 - K-Means 聚类</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第八周：深入聚类 - DBSCAN 与业务解读</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">实验</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第一周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第二周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第三周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第四周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第五周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第六周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第七周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第八周：课堂练习与实验</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#boosting-思想简介" id="toc-boosting-思想简介" class="nav-link active" data-scroll-target="#boosting-思想简介">1. Boosting 思想简介</a></li>
  <li><a href="#从-gbdt-到-xgboost" id="toc-从-gbdt-到-xgboost" class="nav-link" data-scroll-target="#从-gbdt-到-xgboost">2. 从 GBDT 到 XGBoost</a></li>
  <li><a href="#使用-xgboost-进行回归" id="toc-使用-xgboost-进行回归" class="nav-link" data-scroll-target="#使用-xgboost-进行回归">3. 使用 XGBoost 进行回归</a>
  <ul class="collapse">
  <li><a href="#常用参数解释-直观理解" id="toc-常用参数解释-直观理解" class="nav-link" data-scroll-target="#常用参数解释-直观理解">3.1 常用参数解释 (直观理解)</a></li>
  <li><a href="#实践示例数据集训练-xgboost" id="toc-实践示例数据集训练-xgboost" class="nav-link" data-scroll-target="#实践示例数据集训练-xgboost">3.2 实践：示例数据集训练 XGBoost</a></li>
  </ul></li>
  <li><a href="#xgboost-参数调优" id="toc-xgboost-参数调优" class="nav-link" data-scroll-target="#xgboost-参数调优">4. XGBoost 参数调优</a></li>
  <li><a href="#小组项目二xgboost-模型优化与报告" id="toc-小组项目二xgboost-模型优化与报告" class="nav-link" data-scroll-target="#小组项目二xgboost-模型优化与报告">5. 小组项目二：XGBoost 模型优化与报告</a></li>
  <li><a href="#本周总结" id="toc-本周总结" class="nav-link" data-scroll-target="#本周总结">6. 本周总结</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week6_lecture.html"><span class="chapter-title">第六周：回归算法进阶 - XGBoost 与模型优化</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">第六周：回归算法进阶 - XGBoost 与模型优化</span></h1>
<p class="subtitle lead">掌握强大的 Boosting 算法，精进房价预测模型</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>上周我们学习了线性回归、多项式回归以及正则化技术。本周，我们将学习一种在各种数据竞赛和实际应用中都表现极为出色的集成学习算法——<strong>XGBoost (Extreme Gradient Boosting, 极限梯度提升算法)</strong>。该算法由陈天奇等人于2014年提出，现已成为机器学习领域最受欢迎的算法之一。我们将理解 Boosting 的思想，掌握 XGBoost 的使用，并将其应用于我们的房价预测项目（项目二）的优化中。</p>
<div class="callout-info" title="项目二进展">
<p>请确保你已经完成了项目二的基础模型构建（线性回归）以及初步的改进尝试（多项式回归/正则化）。本周我们将使用 XGBoost 来进一步提升模型性能。</p>
</div>
<section id="boosting-思想简介" class="level2">
<h2 class="anchored" data-anchor-id="boosting-思想简介">1. Boosting 思想简介</h2>
<p>我们在第四周学习了 Bagging（以随机森林为代表），它通过并行训练多个独立的基学习器（决策树）并聚合结果来提高性能。<strong>Boosting</strong> 是另一种强大的集成学习思想，它的工作方式与 Bagging 不同：</p>
<ul>
<li><strong>串行训练:</strong> Boosting 算法<strong>依次</strong>训练基学习器（通常也是决策树）。</li>
<li><strong>关注错误:</strong> 每个新的基学习器都<strong>重点关注</strong>前面学习器<strong>预测错误</strong>的样本。</li>
<li><strong>加权组合:</strong> 最终的模型是所有基学习器的<strong>加权组合</strong>，表现好的学习器权重更大。</li>
</ul>
<p>简单来说，Boosting 就像一个学习小组，第一个同学先学一遍，然后第二个同学重点学习第一个同学没掌握好的知识点，第三个同学再重点学习前两个同学都没掌握好的… 最后综合所有同学的知识。</p>
</section>
<section id="从-gbdt-到-xgboost" class="level2">
<h2 class="anchored" data-anchor-id="从-gbdt-到-xgboost">2. 从 GBDT 到 XGBoost</h2>
<p><strong>梯度提升决策树 (Gradient Boosting Decision Tree, GBDT)</strong> 是 Boosting 思想的一个经典实现。它使用梯度下降的思想来优化损失函数，每一棵新树都拟合前面所有树预测结果的<strong>残差（Residuals）</strong> 的负梯度。</p>
<p><strong>XGBoost (Extreme Gradient Boosting)</strong> 是 GBDT 的一种<strong>高效、灵活且可扩展</strong>的实现。它在 GBDT 的基础上做了许多工程和算法上的优化，使其成为目前最流行、性能最好的机器学习算法之一。</p>
<p><strong>XGBoost 的主要优势:</strong></p>
<ul>
<li><strong>正则化:</strong> 内置了 L1 和 L2 正则化项，有助于防止过拟合。</li>
<li><strong>缺失值处理:</strong> 能够自动处理数据中的缺失值。</li>
<li><strong>并行处理:</strong> 在特征层面支持并行计算，训练速度更快。</li>
<li><strong>内置交叉验证:</strong> 可以在训练过程中进行交叉验证。</li>
<li><strong>树剪枝:</strong> 包含更优化的剪枝策略。</li>
<li><strong>灵活性:</strong> 支持自定义优化目标和评估指标。</li>
</ul>
</section>
<section id="使用-xgboost-进行回归" class="level2">
<h2 class="anchored" data-anchor-id="使用-xgboost-进行回归">3. 使用 XGBoost 进行回归</h2>
<p>XGBoost 有自己独立的 Python 库 <code>xgboost</code>。我们需要先安装它（如果你的 Anaconda 环境没有预装的话）： <code>pip install xgboost</code> 或 <code>conda install py-xgboost</code></p>
<p>然后，我们可以使用 <code>XGBRegressor</code> 类来进行回归任务。</p>
<div id="f80e0d43" class="cell" data-execution_count="1">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> xgboost <span class="im">as</span> xgb</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> mean_squared_error, r2_score</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 假设线性回归数据已准备好</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">0</span>)</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>X_lin <span class="op">=</span> <span class="dv">2</span> <span class="op">*</span> np.random.rand(<span class="dv">100</span>, <span class="dv">1</span>)</span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>y_lin <span class="op">=</span> <span class="dv">4</span> <span class="op">+</span> <span class="dv">3</span> <span class="op">*</span> X_lin <span class="op">+</span> np.random.randn(<span class="dv">100</span>, <span class="dv">1</span>)</span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>X_train_lin, X_test_lin, y_train_lin, y_test_lin <span class="op">=</span> train_test_split(</span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>    X_lin, y_lin, test_size<span class="op">=</span><span class="fl">0.2</span>, random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 假设已有 X_train, X_test, y_train, y_test (来自项目二预处理后的数据) ---</span></span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 如果没有，需要重新加载数据并划分</span></span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a><span class="co"># 示例：使用上周的线性数据 X_train_lin, X_test_lin, y_train_lin, y_test_lin</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a><span class="co"># 注意：XGBoost 对特征缩放不敏感，但如果之前做了缩放也没关系</span></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 训练 XGBoost 回归模型 ---</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 创建模型实例 (常用参数解释见下文)</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a>xgb_reg <span class="op">=</span> xgb.XGBRegressor(objective<span class="op">=</span><span class="st">'reg:squarederror'</span>, <span class="co"># 回归任务，目标是最小化平方误差</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a>                           n_estimators<span class="op">=</span><span class="dv">100</span>,         <span class="co"># 树的数量 (基学习器数量)</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a>                           learning_rate<span class="op">=</span><span class="fl">0.1</span>,        <span class="co"># 学习率 (步长)，控制每棵树的贡献，防止过拟合</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a>                           max_depth<span class="op">=</span><span class="dv">3</span>,              <span class="co"># 每棵树的最大深度</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>                           subsample<span class="op">=</span><span class="fl">0.8</span>,            <span class="co"># 训练每棵树时随机抽取的样本比例</span></span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a>                           colsample_bytree<span class="op">=</span><span class="fl">0.8</span>,     <span class="co"># 训练每棵树时随机抽取的特征比例</span></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a>                           gamma<span class="op">=</span><span class="dv">0</span>,                  <span class="co"># 控制是否后剪枝的参数 (越大越保守)</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>                           reg_alpha<span class="op">=</span><span class="dv">0</span>,              <span class="co"># L1 正则化项系数</span></span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a>                           reg_lambda<span class="op">=</span><span class="dv">1</span>,             <span class="co"># L2 正则化项系数 (默认)</span></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a>                           random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>                           n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 拟合模型</span></span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a><span class="co"># XGBoost 可以使用验证集进行早停 (Early Stopping) 来防止过拟合，提高效率</span></span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="co"># eval_set: 提供一个或多个验证集用于评估</span></span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a><span class="co"># early_stopping_rounds: 如果验证集上的评估指标连续 N 轮没有改善，则停止训练</span></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>eval_set <span class="op">=</span> [(X_train_lin, y_train_lin), (X_test_lin, y_test_lin)]</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a>xgb_reg.fit(X_train_lin, y_train_lin,</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a>            eval_set<span class="op">=</span>eval_set,</span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>            eval_metric<span class="op">=</span><span class="st">'rmse'</span>, <span class="co"># 指定在验证集上监控的指标</span></span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a>            early_stopping_rounds<span class="op">=</span><span class="dv">10</span>,</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a>            verbose<span class="op">=</span><span class="va">False</span>) <span class="co"># verbose=True 会打印每一轮的评估结果</span></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 进行预测 ---</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>y_pred_xgb <span class="op">=</span> xgb_reg.predict(X_test_lin)</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 评估模型 ---</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- XGBoost 回归评估 ---"</span>)</span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>mse_xgb <span class="op">=</span> mean_squared_error(y_test_lin, y_pred_xgb)</span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a>rmse_xgb <span class="op">=</span> np.sqrt(mse_xgb)</span>
<span id="cb1-52"><a href="#cb1-52" aria-hidden="true" tabindex="-1"></a>r2_xgb <span class="op">=</span> r2_score(y_test_lin, y_pred_xgb)</span>
<span id="cb1-53"><a href="#cb1-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-54"><a href="#cb1-54" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"XGBoost 均方根误差 (RMSE): </span><span class="sc">{</span>rmse_xgb<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-55"><a href="#cb1-55" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"XGBoost R 方 (R-squared): </span><span class="sc">{</span>r2_xgb<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-56"><a href="#cb1-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-57"><a href="#cb1-57" aria-hidden="true" tabindex="-1"></a><span class="co"># --- (可选) 对比线性回归结果 ---</span></span>
<span id="cb1-58"><a href="#cb1-58" aria-hidden="true" tabindex="-1"></a><span class="co"># from sklearn.linear_model import LinearRegression # 需要导入</span></span>
<span id="cb1-59"><a href="#cb1-59" aria-hidden="true" tabindex="-1"></a><span class="co"># lin_reg = LinearRegression().fit(X_train_lin, y_train_lin)</span></span>
<span id="cb1-60"><a href="#cb1-60" aria-hidden="true" tabindex="-1"></a><span class="co"># y_pred_lin = lin_reg.predict(X_test_lin)</span></span>
<span id="cb1-61"><a href="#cb1-61" aria-hidden="true" tabindex="-1"></a><span class="co"># rmse_lin = np.sqrt(mean_squared_error(y_test_lin, y_pred_lin))</span></span>
<span id="cb1-62"><a href="#cb1-62" aria-hidden="true" tabindex="-1"></a><span class="co"># r2_lin = r2_score(y_test_lin, y_pred_lin)</span></span>
<span id="cb1-63"><a href="#cb1-63" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"\n线性回归 RMSE: {rmse_lin:.4f}")</span></span>
<span id="cb1-64"><a href="#cb1-64" aria-hidden="true" tabindex="-1"></a><span class="co"># print(f"线性回归 R 方: {r2_lin:.4f}")</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
--- XGBoost 回归评估 ---
XGBoost 均方根误差 (RMSE): 1.0878
XGBoost R 方 (R-squared): 0.5515</code></pre>
</div>
</div>
<section id="常用参数解释-直观理解" class="level3">
<h3 class="anchored" data-anchor-id="常用参数解释-直观理解">3.1 常用参数解释 (直观理解)</h3>
<ul>
<li><code>objective</code>: 指定学习任务和对应的损失函数。回归常用 <code>'reg:squarederror'</code> (均方误差)。分类常用 <code>'binary:logistic'</code> (二分类对数损失) 或 <code>'multi:softmax'</code> / <code>'multi:softprob'</code> (多分类)。</li>
<li><code>n_estimators</code>: 树的数量。太少可能欠拟合，太多可能过拟合（但有早停可以缓解）。通常从 100 开始尝试。</li>
<li><code>learning_rate</code> (或 <code>eta</code>): 学习率。较小的值（如 0.01-0.3）通常需要更多的树 (<code>n_estimators</code>)，但模型更稳健。</li>
<li><code>max_depth</code>: 每棵树的最大深度。控制树的复杂度，防止过拟合。常用 3-10。</li>
<li><code>subsample</code>: 训练每棵树时使用的样本比例。引入随机性，防止过拟合。常用 0.5-1.0。</li>
<li><code>colsample_bytree</code>: 构建每棵树时使用的特征比例。引入随机性，防止过拟合。常用 0.5-1.0。</li>
<li><code>gamma</code>: 节点分裂所需的最小损失降低。值越大，算法越保守，越不容易分裂。</li>
<li><code>reg_alpha</code> (L1) / <code>reg_lambda</code> (L2): 正则化系数。控制模型的复杂度。</li>
</ul>
<div class="callout callout-style-default callout-tip callout-titled" title="AI 辅助 XGBoost 学习">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
AI 辅助 XGBoost 学习
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>“解释 XGBoost 中的 <code>learning_rate</code> 和 <code>n_estimators</code> 参数如何相互影响？”</li>
<li>“XGBoost 如何处理缺失值？”</li>
<li>“对比 XGBoost 和 RandomForest 的主要区别。”</li>
<li>“查找 XGBoost <code>XGBRegressor</code> 的官方文档中关于 <code>subsample</code> 和 <code>colsample_bytree</code> 参数的详细说明。”</li>
<li>“什么是 XGBoost 的早停 (Early Stopping) 机制？它有什么好处？”</li>
</ul>
</div>
</div>
</section>
<section id="实践示例数据集训练-xgboost" class="level3">
<h3 class="anchored" data-anchor-id="实践示例数据集训练-xgboost">3.2 实践：示例数据集训练 XGBoost</h3>
<p>请使用一个简单回归数据集（例如上周的多项式数据 <code>X_poly</code>, <code>y_poly</code>，或者老师提供的数据），完成以下步骤：</p>
<ol type="1">
<li>划分训练集和测试集。</li>
<li>训练一个 <code>XGBRegressor</code> 模型（可以先用默认或推荐参数）。</li>
<li>训练一个 <code>LinearRegression</code> 模型作为对比。</li>
<li>在测试集上进行预测。</li>
<li>计算并比较两个模型的 RMSE 和 R²。观察 XGBoost 是否比线性回归表现更好。</li>
</ol>
</section>
</section>
<section id="xgboost-参数调优" class="level2">
<h2 class="anchored" data-anchor-id="xgboost-参数调优">4. XGBoost 参数调优</h2>
<p>XGBoost 有很多超参数，找到最优组合对模型性能至关重要。手动调优效率低下，我们可以使用系统性的方法：</p>
<ul>
<li><strong>调优策略:</strong> 通常建议按重要性顺序调整参数：
<ol type="1">
<li>先确定一个较高的 <code>learning_rate</code> (如 0.1) 和合适的 <code>n_estimators</code> (通过早停机制或初步估计)。</li>
<li>调优树相关的参数 <code>max_depth</code>, <code>min_child_weight</code> (控制叶子节点样本权重和的阈值), <code>gamma</code>。</li>
<li>调优采样参数 <code>subsample</code>, <code>colsample_bytree</code>。</li>
<li>调优正则化参数 <code>reg_alpha</code>, <code>reg_lambda</code>。</li>
<li>最后，降低 <code>learning_rate</code>，同时相应增加 <code>n_estimators</code> (通常成反比增加)，看是否能进一步提升。</li>
</ol></li>
<li><strong>工具:</strong>
<ul>
<li><strong>GridSearchCV:</strong> 尝试所有参数组合，计算量大，但能找到全局最优（在给定网格内）。</li>
<li><strong>RandomizedSearchCV:</strong> 从参数分布中随机采样组合进行尝试，计算量较小，能在合理时间内找到较优解，适合参数空间很大时。</li>
<li><strong>贝叶斯优化库 (如 Hyperopt, Optuna):</strong> 更智能的调优方法，根据历史评估结果来选择下一个尝试的参数组合，效率更高。</li>
</ul></li>
</ul>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV, RandomizedSearchCV</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> scipy.stats <span class="im">import</span> uniform, randint <span class="co"># 用于 RandomizedSearchCV 的参数分布</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 使用 GridSearchCV 调优 XGBoost (示例) ---</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># (注意：实际调优可能需要更细致的参数范围和更多折数，会非常耗时)</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>param_grid_xgb <span class="op">=</span> {</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">7</span>],</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: [<span class="fl">0.05</span>, <span class="fl">0.1</span>, <span class="fl">0.2</span>],</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">100</span>, <span class="dv">200</span>],</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: [<span class="fl">0.7</span>, <span class="fl">0.8</span>],</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: [<span class="fl">0.7</span>, <span class="fl">0.8</span>]</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 可以加入 gamma, reg_alpha, reg_lambda 等</span></span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>xgb_reg_tune <span class="op">=</span> xgb.XGBRegressor(objective<span class="op">=</span><span class="st">'reg:squarederror'</span>, random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>grid_search_xgb <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>xgb_reg_tune,</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>                               param_grid<span class="op">=</span>param_grid_xgb,</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a>                               scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>, <span class="co"># 使用负 RMSE，因为 GridSearchCV 默认找最大值</span></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>                               cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a>                               verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span class="co"># grid_search_xgb.fit(X_train, y_train) # 在项目数据上执行</span></span>
<span id="cb3-25"><a href="#cb3-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-26"><a href="#cb3-26" aria-hidden="true" tabindex="-1"></a><span class="co"># print("GridSearchCV 最优参数:", grid_search_xgb.best_params_)</span></span>
<span id="cb3-27"><a href="#cb3-27" aria-hidden="true" tabindex="-1"></a><span class="co"># print("GridSearchCV 最优负 RMSE:", grid_search_xgb.best_score_)</span></span>
<span id="cb3-28"><a href="#cb3-28" aria-hidden="true" tabindex="-1"></a><span class="co"># best_xgb_reg = grid_search_xgb.best_estimator_</span></span>
<span id="cb3-29"><a href="#cb3-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-30"><a href="#cb3-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-31"><a href="#cb3-31" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 使用 RandomizedSearchCV 调优 XGBoost (示例) ---</span></span>
<span id="cb3-32"><a href="#cb3-32" aria-hidden="true" tabindex="-1"></a>param_dist_xgb <span class="op">=</span> {</span>
<span id="cb3-33"><a href="#cb3-33" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: randint(<span class="dv">3</span>, <span class="dv">10</span>), <span class="co"># 3 到 9 的随机整数</span></span>
<span id="cb3-34"><a href="#cb3-34" aria-hidden="true" tabindex="-1"></a>    <span class="st">'learning_rate'</span>: uniform(<span class="fl">0.01</span>, <span class="fl">0.3</span>), <span class="co"># 0.01 到 0.31 之间的均匀分布</span></span>
<span id="cb3-35"><a href="#cb3-35" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: randint(<span class="dv">100</span>, <span class="dv">500</span>),</span>
<span id="cb3-36"><a href="#cb3-36" aria-hidden="true" tabindex="-1"></a>    <span class="st">'subsample'</span>: uniform(<span class="fl">0.6</span>, <span class="fl">0.4</span>), <span class="co"># 0.6 到 1.0 之间</span></span>
<span id="cb3-37"><a href="#cb3-37" aria-hidden="true" tabindex="-1"></a>    <span class="st">'colsample_bytree'</span>: uniform(<span class="fl">0.6</span>, <span class="fl">0.4</span>),</span>
<span id="cb3-38"><a href="#cb3-38" aria-hidden="true" tabindex="-1"></a>    <span class="st">'gamma'</span>: uniform(<span class="dv">0</span>, <span class="fl">0.5</span>),</span>
<span id="cb3-39"><a href="#cb3-39" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reg_alpha'</span>: uniform(<span class="dv">0</span>, <span class="dv">1</span>),</span>
<span id="cb3-40"><a href="#cb3-40" aria-hidden="true" tabindex="-1"></a>    <span class="st">'reg_lambda'</span>: uniform(<span class="fl">0.5</span>, <span class="fl">1.5</span>) <span class="co"># 0.5 到 2.0 之间</span></span>
<span id="cb3-41"><a href="#cb3-41" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb3-42"><a href="#cb3-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-43"><a href="#cb3-43" aria-hidden="true" tabindex="-1"></a>random_search_xgb <span class="op">=</span> RandomizedSearchCV(estimator<span class="op">=</span>xgb_reg_tune,</span>
<span id="cb3-44"><a href="#cb3-44" aria-hidden="true" tabindex="-1"></a>                                       param_distributions<span class="op">=</span>param_dist_xgb,</span>
<span id="cb3-45"><a href="#cb3-45" aria-hidden="true" tabindex="-1"></a>                                       n_iter<span class="op">=</span><span class="dv">50</span>, <span class="co"># 尝试 50 组随机参数组合</span></span>
<span id="cb3-46"><a href="#cb3-46" aria-hidden="true" tabindex="-1"></a>                                       scoring<span class="op">=</span><span class="st">'neg_root_mean_squared_error'</span>,</span>
<span id="cb3-47"><a href="#cb3-47" aria-hidden="true" tabindex="-1"></a>                                       cv<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb3-48"><a href="#cb3-48" aria-hidden="true" tabindex="-1"></a>                                       verbose<span class="op">=</span><span class="dv">1</span>,</span>
<span id="cb3-49"><a href="#cb3-49" aria-hidden="true" tabindex="-1"></a>                                       random_state<span class="op">=</span><span class="dv">42</span>,</span>
<span id="cb3-50"><a href="#cb3-50" aria-hidden="true" tabindex="-1"></a>                                       n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-51"><a href="#cb3-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-52"><a href="#cb3-52" aria-hidden="true" tabindex="-1"></a><span class="co"># random_search_xgb.fit(X_train, y_train) # 在项目数据上执行</span></span>
<span id="cb3-53"><a href="#cb3-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-54"><a href="#cb3-54" aria-hidden="true" tabindex="-1"></a><span class="co"># print("RandomizedSearchCV 最优参数:", random_search_xgb.best_params_)</span></span>
<span id="cb3-55"><a href="#cb3-55" aria-hidden="true" tabindex="-1"></a><span class="co"># print("RandomizedSearchCV 最优负 RMSE:", random_search_xgb.best_score_)</span></span>
<span id="cb3-56"><a href="#cb3-56" aria-hidden="true" tabindex="-1"></a><span class="co"># best_xgb_reg_random = random_search_xgb.best_estimator_</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="小组项目二xgboost-模型优化与报告" class="level2">
<h2 class="anchored" data-anchor-id="小组项目二xgboost-模型优化与报告">5. 小组项目二：XGBoost 模型优化与报告</h2>
<p>本周需要使用 XGBoost 来优化你的房价预测模型，并完成最终报告。</p>
<ul>
<li><strong>任务:</strong>
<ol type="1">
<li><strong>训练 XGBoost 模型:</strong> 在你的预处理数据上训练一个 <code>XGBRegressor</code> 模型。记得使用验证集和早停机制 (<code>fit</code> 方法中的 <code>eval_set</code>, <code>eval_metric</code>, <code>early_stopping_rounds</code>)。</li>
<li><strong>评估初始 XGBoost:</strong> 评估该模型的性能 (RMSE, R²)，并与之前的线性回归、多项式回归、正则化回归模型进行比较。</li>
<li><strong>参数调优:</strong>
<ul>
<li>选择一种调优方法（GridSearchCV 或 RandomizedSearchCV）。</li>
<li>定义合适的参数搜索空间 (<code>param_grid</code> 或 <code>param_distributions</code>)，至少包含 <code>n_estimators</code>, <code>learning_rate</code>, <code>max_depth</code>, <code>subsample</code>, <code>colsample_bytree</code> 等关键参数。</li>
<li>执行参数搜索，找到最优的超参数组合。<strong>（注意：这可能非常耗时，可以先用较小的搜索空间或较少的迭代次数进行尝试）。</strong></li>
</ul></li>
<li><strong>评估最优 XGBoost:</strong> 使用找到的最佳超参数训练最终的 XGBoost 模型，并在<strong>测试集</strong>上评估其性能。</li>
<li><strong>结果对比与分析:</strong>
<ul>
<li>全面比较所有尝试过的模型（线性、多项式、正则化、初始 XGBoost、调优后 XGBoost）在测试集上的最终性能。哪个模型效果最好？</li>
<li>(可选) 分析最优 XGBoost 模型的特征重要性 (<code>feature_importances_</code>)。哪些因素对房价影响最大？</li>
<li>总结项目二的整个流程、模型选择、调优过程、最终结果以及对房价预测任务的理解和洞察。</li>
</ul></li>
</ol></li>
<li><strong>提交:</strong>
<ul>
<li>最终的代码，包含所有模型训练、评估、调优的代码、结果和分析。</li>
<li>一份简洁的项目报告，清晰呈现项目流程、方法、结果对比、最终模型性能、结论和思考。</li>
</ul></li>
<li><strong>DDL:</strong> 第七周第一次课前。</li>
</ul>
</section>
<section id="本周总结" class="level2">
<h2 class="anchored" data-anchor-id="本周总结">6. 本周总结</h2>
<p>本周我们学习了强大的 Boosting 算法，特别是 XGBoost。我们了解了它的核心思想、优势以及如何在 Scikit-learn 中使用 <code>XGBRegressor</code> 进行回归任务。我们还探讨了 XGBoost 的关键参数和调优策略，包括使用 GridSearchCV 和 RandomizedSearchCV。最后，我们将 XGBoost 应用于项目二的优化，力求构建更精准的房价预测模型。</p>
<p><strong>下周我们将进入无监督学习领域，学习第一个聚类算法——K-Means！</strong></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week5_lecture.html" class="pagination-link" aria-label="第五周：回归算法启程 - 线性回归与多项式回归">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">第五周：回归算法启程 - 线性回归与多项式回归</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week7_lecture.html" class="pagination-link" aria-label="第七周：无监督学习初探 - K-Means 聚类">
        <span class="nav-page-text"><span class="chapter-title">第七周：无监督学习初探 - K-Means 聚类</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>