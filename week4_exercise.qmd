---
title: "第四周：课堂练习与实验"
subtitle: "决策树、随机森林与模型调优"
---

本周我们将深入研究基于树的模型——决策树和随机森林，并学习重要的模型评估和优化技术：交叉验证与网格搜索。

## 准备工作

确保导入本周所需的库：

```python
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.tree import DecisionTreeClassifier, plot_tree
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, classification_report, confusion_matrix
from sklearn.datasets import make_classification
from sklearn.linear_model import LogisticRegression # For comparison in CV

# 设置 matplotlib 绘图样式 (可选)
plt.style.use('seaborn-v0_8-whitegrid')

# --- 复用上周的数据准备 ---
# 生成数据
X_cls, y_cls = make_classification(n_samples=500, n_features=10, n_informative=5,
                                   n_redundant=2, n_classes=2, random_state=42)
feature_names = [f'feature_{i}' for i in range(X_cls.shape[1])]
# 划分数据
X_train, X_test, y_train, y_test = train_test_split(
    X_cls, y_cls, test_size=0.3, random_state=42, stratify=y_cls
)
# 特征缩放 (虽然树模型对缩放不敏感，但保持一致性，且便于后续比较)
scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

## 练习 1: 决策树实践与可视化

**目标:** 训练决策树模型并理解其结构。

1.  **训练决策树:**
    *   创建一个 `DecisionTreeClassifier` 模型实例。为了便于初始可视化，可以先设置一个较小的 `max_depth`，例如 `max_depth=3`。设置 `random_state=42`。
    *   使用 `X_train_scaled` 和 `y_train` 训练模型。
2.  **评估模型:**
    *   对 `X_test_scaled` 进行预测。
    *   计算并打印准确率和分类报告。
3.  **可视化决策树:**
    *   使用 `plot_tree()` 函数将训练好的决策树可视化。
    *   设置 `filled=True`, `rounded=True`, `class_names=['Class 0', 'Class 1']`, `feature_names=feature_names`。
    *   调整 `figsize` 以获得清晰的图像 (例如 `figsize=(15, 8)`)。
    *   调用 `plt.show()` 显示图像。
    *   **解读:** 尝试追踪几个样本从根节点到叶节点的路径，理解决策过程。在 Markdown 单元格中描述一个样本的决策路径。

## 练习 2: 理解决策树过拟合

**目标:** 通过调整 `max_depth` 理解决策树的过拟合现象。

1.  **训练不同深度的树:**
    *   创建一个列表存储不同的 `max_depth` 值：`depths = [2, 5, 10, 15, None]` (None 表示不限制深度)。
    *   创建两个空列表 `train_accuracies` 和 `test_accuracies` 用于存储准确率。
    *   使用 `for` 循环遍历 `depths` 列表：
        *   在循环内部，创建 `DecisionTreeClassifier` 实例，设置 `max_depth` 为当前循环的值，`random_state=42`。
        *   训练模型 (`fit(X_train_scaled, y_train)`)。
        *   计算模型在**训练集**上的准确率 (`score(X_train_scaled, y_train)`)，并添加到 `train_accuracies` 列表。
        *   计算模型在**测试集**上的准确率 (`score(X_test_scaled, y_test)`)，并添加到 `test_accuracies` 列表。
2.  **分析结果:**
    *   绘制一个折线图：
        *   x 轴刻度标签可以使用 `[str(d) for d in depths]` 来处理 `None`。
        *   y 轴为准确率。
        *   绘制训练集准确率曲线 (`train_accuracies`) 和测试集准确率曲线 (`test_accuracies`)，并添加图例。
        *   添加标题 ("Decision Tree Accuracy vs. Max Depth") 和坐标轴标签 ("Max Depth", "Accuracy")。
        *   调用 `plt.show()` 显示图像。
    *   **观察与思考:**
        *   在 Markdown 单元格中描述：随着 `max_depth` 的增加，训练集准确率和测试集准确率分别如何变化？
        *   哪个 `max_depth` 值在测试集上表现最好？
        *   当 `max_depth` 非常大或不限制时，训练集和测试集准确率的差距说明了什么？这就是**过拟合**。

## 练习 3: 随机森林实践与特征重要性

**目标:** 训练随机森林模型，评估其性能，并提取特征重要性。

1.  **训练随机森林:**
    *   创建一个 `RandomForestClassifier` 模型实例。设置 `n_estimators=100`, `max_depth=10` (可以根据练习 2 的结果选择一个较优的深度), `random_state=42`, `n_jobs=-1`。
    *   使用 `X_train_scaled` 和 `y_train` 训练模型。
2.  **评估模型:**
    *   对 `X_test_scaled` 进行预测。
    *   计算并打印准确率和分类报告。
    *   **对比:** 在 Markdown 单元格中比较随机森林的测试集准确率与练习 2 中最佳单棵决策树的测试集准确率。随机森林是否有提升？

3.  **特征重要性:**
    *   获取训练好的随机森林模型的 `feature_importances_` 属性。
    *   创建一个 Pandas DataFrame，包含两列：'Feature' (值为 `feature_names`) 和 'Importance' (值为重要性得分)。
    *   按 'Importance' 列降序排序该 DataFrame。
    *   使用 `seaborn.barplot()` 可视化特征重要性（y 轴为特征名，x 轴为重要性得分）。
    *   添加标题 ("Feature Importance (Random Forest)")。
    *   调用 `plt.show()` 显示图像。
    *   **解读:** 在 Markdown 单元格中列出最重要的 3 个特征。

## 练习 4: 交叉验证 (Cross-Validation)

**目标:** 使用交叉验证更可靠地评估模型性能。

1.  **对逻辑回归进行交叉验证:**
    *   创建一个 `LogisticRegression` 实例 (`random_state=42`)。
    *   使用 `cross_val_score()` 对该模型在**整个训练集** (`X_train_scaled`, `y_train`) 上进行 5 折交叉验证 (`cv=5`)。
    *   设置 `scoring='accuracy'`。
    *   打印返回的包含 5 个准确率得分的列表 `lr_cv_scores`。
    *   计算并打印这 5 个得分的平均值和标准差 (`lr_cv_scores.mean()`, `lr_cv_scores.std()`)。

2.  **对随机森林进行交叉验证:**
    *   创建一个 `RandomForestClassifier` 实例（使用练习 3 的参数：`n_estimators=100`, `max_depth=10`, `random_state=42`, `n_jobs=-1`）。
    *   同样使用 `cross_val_score()` 进行 5 折交叉验证，评估准确率。
    *   打印每次验证的准确率以及平均准确率和标准差。

3.  **比较:** 在 Markdown 单元格中比较两种模型在交叉验证中的平均性能和稳定性（标准差）。哪个模型看起来更好？

## 练习 5: 网格搜索 (Grid Search) 调优

**目标:** 使用 GridSearchCV 自动寻找随机森林的最佳超参数。

1.  **定义参数网格:**
    *   为 `RandomForestClassifier` 创建一个参数字典 `param_grid`。
    *   至少包含 `n_estimators` (例如 `[50, 100, 150]`), `max_depth` (例如 `[5, 10, None]`), `min_samples_leaf` (例如 `[1, 3, 5]`) 这几个参数的不同候选值。可以根据计算时间适当调整范围。
2.  **创建 GridSearchCV 对象:**
    *   实例化 `GridSearchCV`。
    *   传入 `RandomForestClassifier(random_state=42, n_jobs=-1)` 作为 `estimator`。
    *   传入 `param_grid`。
    *   设置 `cv=3` (为了节省时间，实际中可用 5 或 10)。
    *   设置 `scoring='accuracy'`。
    *   设置 `verbose=1` 以查看搜索过程。
3.  **执行搜索:**
    *   在训练集 (`X_train_scaled`, `y_train`) 上调用 `fit()` 方法执行网格搜索。**注意：这可能需要几分钟时间。**
4.  **查看结果:**
    *   打印 `grid_search.best_params_` 查看找到的最佳参数组合。
    *   打印 `grid_search.best_score_` 查看最佳参数组合下的交叉验证平均准确率。
5.  **评估最优模型:**
    *   获取最佳模型: `best_rf = grid_search.best_estimator_`。
    *   使用 `best_rf` 对**测试集** (`X_test_scaled`) 进行预测。
    *   计算并打印最优模型在测试集上的准确率和分类报告。
    *   **对比:** 在 Markdown 单元格中比较这个最优模型的测试集性能与练习 3 中的随机森林模型（使用默认或手动选择的参数）的性能。网格搜索是否有带来提升？

## 练习 6: 项目一 - 模型优化与最终报告

**目标:** 应用本周所学优化项目一的模型，并准备最终报告。

1.  **应用随机森林:** 在你的项目一预处理数据上训练随机森林模型。
2.  **交叉验证评估:** 使用 `cross_val_score` 评估随机森林的性能，并与上周的 LR 和 SVM 结果比较（比较交叉验证的平均得分）。
3.  **网格搜索调优:**
    *   为你的随机森林模型定义合适的参数网格（可以参考练习 5，但根据你的数据和计算能力调整）。
    *   使用 `GridSearchCV` 寻找最佳超参数。记录最佳参数和对应的交叉验证分数。
4.  **最终评估与分析:**
    *   使用找到的最佳模型在**测试集**上进行评估（准确率、分类报告、混淆矩阵、ROC AUC）。
    *   在 Markdown 单元格或报告中，**清晰地比较**所有尝试过的模型（LR, SVM, 初始 RF, 调优后 RF）在**测试集**上的最终性能。哪个模型是你最终选择的模型？为什么？
    *   分析最优模型的特征重要性 (`feature_importances_`)。哪些特征对预测你的目标变量最重要？
5.  **撰写报告:**
    *   更新你的 Jupyter Notebook，包含所有优化步骤和分析。
    *   开始撰写项目一的最终报告（`.md` 或 `.pdf` 格式），总结整个项目流程、方法、结果、分析和结论。报告结构可以参考第十六周讲义中的建议。

**通过本周的练习，你将掌握更强大的模型和优化技巧，为解决更复杂的机器学习问题做好准备！**