<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.5.57">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>第四周：决策树与随机森林 - 模型优化初探 – 机器学习Python</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { display: inline-block; text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="site_libs/quarto-nav/quarto-nav.js"></script>
<script src="site_libs/quarto-nav/headroom.min.js"></script>
<script src="site_libs/clipboard/clipboard.min.js"></script>
<script src="site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="site_libs/quarto-search/fuse.min.js"></script>
<script src="site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="./">
<link href="./week5_lecture.html" rel="next">
<link href="./week3_lecture.html" rel="prev">
<script src="site_libs/quarto-html/quarto.js"></script>
<script src="site_libs/quarto-html/popper.min.js"></script>
<script src="site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="site_libs/quarto-html/anchor.min.js"></script>
<link href="site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="site_libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="site_libs/bootstrap/bootstrap.min.js"></script>
<link href="site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="site_libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "sidebar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "start",
  "type": "textbox",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>


<link rel="stylesheet" href="styles/custom.css">
</head>

<body class="nav-sidebar floating">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top">
  <nav class="quarto-secondary-nav">
    <div class="container-fluid d-flex">
      <button type="button" class="quarto-btn-toggle btn" data-bs-toggle="collapse" role="button" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
        <i class="bi bi-layout-text-sidebar-reverse"></i>
      </button>
        <nav class="quarto-page-breadcrumbs" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week4_lecture.html"><span class="chapter-title">第四周：决策树与随机森林 - 模型优化初探</span></a></li></ol></nav>
        <a class="flex-grow-1" role="navigation" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item" aria-controls="quarto-sidebar" aria-expanded="false" aria-label="Toggle sidebar navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">      
        </a>
      <button type="button" class="btn quarto-search-button" aria-label="Search" onclick="window.quartoOpenSearch();">
        <i class="bi bi-search"></i>
      </button>
    </div>
  </nav>
</header>
<!-- content -->
<div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article">
<!-- sidebar -->
  <nav id="quarto-sidebar" class="sidebar collapse collapse-horizontal quarto-sidebar-collapse-item sidebar-navigation floating overflow-auto">
    <div class="pt-lg-2 mt-2 text-left sidebar-header">
    <div class="sidebar-title mb-0 py-0">
      <a href="./">机器学习Python</a> 
    </div>
      </div>
        <div class="mt-2 flex-shrink-0 align-items-center">
        <div class="sidebar-search">
        <div id="quarto-search" class="" title="Search"></div>
        </div>
        </div>
    <div class="sidebar-menu-container"> 
    <ul class="list-unstyled mt-1">
        <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./index.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">index.html</span></a>
  </div>
</li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true">
 <span class="menu-text">讲义</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-1" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-1" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第一周：机器学习世界初探与工具准备</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第二周：数据处理利器 Numpy &amp; Pandas 与项目启动</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第三周：分类算法初探 - 逻辑回归与支持向量机</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_lecture.html" class="sidebar-item-text sidebar-link active"><span class="chapter-title">第四周：决策树与随机森林 - 模型优化初探</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第五周：回归算法启程 - 线性回归与多项式回归</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第六周：回归算法进阶 - XGBoost 与模型优化</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第七周：无监督学习初探 - K-Means 聚类</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_lecture.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第八周：深入聚类 - DBSCAN 与业务解读</span></a>
  </div>
</li>
      </ul>
  </li>
        <li class="sidebar-item sidebar-item-section">
      <div class="sidebar-item-container"> 
            <a class="sidebar-item-text sidebar-link text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true">
 <span class="menu-text">实验</span></a>
          <a class="sidebar-item-toggle text-start" data-bs-toggle="collapse" data-bs-target="#quarto-sidebar-section-2" role="navigation" aria-expanded="true" aria-label="Toggle section">
            <i class="bi bi-chevron-right ms-2"></i>
          </a> 
      </div>
      <ul id="quarto-sidebar-section-2" class="collapse list-unstyled sidebar-section depth1 show">  
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week1_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第一周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week2_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第二周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week3_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第三周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week4_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第四周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week5_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第五周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week6_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第六周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week7_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第七周：课堂练习与实验</span></a>
  </div>
</li>
          <li class="sidebar-item">
  <div class="sidebar-item-container"> 
  <a href="./week8_exercise.html" class="sidebar-item-text sidebar-link"><span class="chapter-title">第八周：课堂练习与实验</span></a>
  </div>
</li>
      </ul>
  </li>
    </ul>
    </div>
</nav>
<div id="quarto-sidebar-glass" class="quarto-sidebar-collapse-item" data-bs-toggle="collapse" data-bs-target=".quarto-sidebar-collapse-item"></div>
<!-- margin-sidebar -->
    <div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
        <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#决策树-decision-tree" id="toc-决策树-decision-tree" class="nav-link active" data-scroll-target="#决策树-decision-tree">1. 决策树 (Decision Tree)</a>
  <ul class="collapse">
  <li><a href="#原理简介-直观理解" id="toc-原理简介-直观理解" class="nav-link" data-scroll-target="#原理简介-直观理解">1.1 原理简介 (直观理解)</a></li>
  <li><a href="#使用-scikit-learn-实现" id="toc-使用-scikit-learn-实现" class="nav-link" data-scroll-target="#使用-scikit-learn-实现">1.2 使用 Scikit-learn 实现</a></li>
  <li><a href="#优缺点" id="toc-优缺点" class="nav-link" data-scroll-target="#优缺点">1.3 优缺点</a></li>
  </ul></li>
  <li><a href="#集成学习-ensemble-learning---随机森林" id="toc-集成学习-ensemble-learning---随机森林" class="nav-link" data-scroll-target="#集成学习-ensemble-learning---随机森林">2. 集成学习 (Ensemble Learning) - 随机森林</a>
  <ul class="collapse">
  <li><a href="#bagging-思想" id="toc-bagging-思想" class="nav-link" data-scroll-target="#bagging-思想">2.1 Bagging 思想</a></li>
  <li><a href="#随机森林的随机" id="toc-随机森林的随机" class="nav-link" data-scroll-target="#随机森林的随机">2.2 随机森林的“随机”</a></li>
  <li><a href="#使用-scikit-learn-实现-1" id="toc-使用-scikit-learn-实现-1" class="nav-link" data-scroll-target="#使用-scikit-learn-实现-1">2.3 使用 Scikit-learn 实现</a></li>
  <li><a href="#随机森林优点" id="toc-随机森林优点" class="nav-link" data-scroll-target="#随机森林优点">2.4 随机森林优点</a></li>
  </ul></li>
  <li><a href="#模型优化交叉验证与网格搜索" id="toc-模型优化交叉验证与网格搜索" class="nav-link" data-scroll-target="#模型优化交叉验证与网格搜索">3. 模型优化：交叉验证与网格搜索</a>
  <ul class="collapse">
  <li><a href="#交叉验证-cross-validation-cv" id="toc-交叉验证-cross-validation-cv" class="nav-link" data-scroll-target="#交叉验证-cross-validation-cv">3.1 交叉验证 (Cross-Validation, CV)</a></li>
  <li><a href="#网格搜索-grid-search" id="toc-网格搜索-grid-search" class="nav-link" data-scroll-target="#网格搜索-grid-search">3.2 网格搜索 (Grid Search)</a></li>
  </ul></li>
  <li><a href="#小组项目一模型优化与最终报告" id="toc-小组项目一模型优化与最终报告" class="nav-link" data-scroll-target="#小组项目一模型优化与最终报告">4. 小组项目一：模型优化与最终报告</a></li>
  <li><a href="#本周总结" id="toc-本周总结" class="nav-link" data-scroll-target="#本周总结">5. 本周总结</a></li>
  </ul>
</nav>
    </div>
<!-- main -->
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default"><nav class="quarto-page-breadcrumbs quarto-title-breadcrumbs d-none d-lg-block" aria-label="breadcrumb"><ol class="breadcrumb"><li class="breadcrumb-item"><a href="./week1_lecture.html">讲义</a></li><li class="breadcrumb-item"><a href="./week4_lecture.html"><span class="chapter-title">第四周：决策树与随机森林 - 模型优化初探</span></a></li></ol></nav>
<div class="quarto-title">
<h1 class="title"><span class="chapter-title">第四周：决策树与随机森林 - 模型优化初探</span></h1>
<p class="subtitle lead">学习基于树的模型，掌握集成学习思想与自动化调优</p>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<p>上周我们学习了逻辑回归和 SVM。本周我们将探索另一类非常流行且直观的分类算法：<strong>决策树 (Decision Tree)</strong>。在此基础上，我们将进一步学习强大的<strong>集成学习 (Ensemble Learning)</strong> 方法——<strong>随机森林 (Random Forest)</strong>。同时，我们还会介绍模型优化的关键技术：<strong>交叉验证 (Cross-Validation)</strong> 和<strong>网格搜索 (Grid Search)</strong>，并将它们应用于项目一的模型优化。</p>
<div class="callout-info" title="项目一模型构建">
<p>请确保你已经提交了使用 LR 和 SVM 构建的项目一模型及评估结果。本周我们将在此基础上进行优化。</p>
</div>
<section id="决策树-decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="决策树-decision-tree">1. 决策树 (Decision Tree)</h2>
<p>决策树是一种模仿人类决策过程的算法。它通过一系列的“是/否”问题（基于特征的判断）来对数据进行划分，最终将样本归入不同的类别。</p>
<section id="原理简介-直观理解" class="level3">
<h3 class="anchored" data-anchor-id="原理简介-直观理解">1.1 原理简介 (直观理解)</h3>
<p>想象一下判断一个西瓜是不是好瓜的过程：</p>
<ol type="1">
<li>先看颜色，是不是青绿色？
<ul>
<li>是：再看根蒂，是不是蜷缩？
<ul>
<li>是：再听声音，是不是浊响？
<ul>
<li>是：好瓜！</li>
<li>否：坏瓜。</li>
</ul></li>
<li>否：坏瓜。</li>
</ul></li>
<li>否：坏瓜。</li>
</ul></li>
</ol>
<p>这就是一个简单的决策树。它包含：</p>
<ul>
<li><strong>根节点 (Root Node):</strong> 第一个问题/判断（如“颜色是青绿吗？”）。</li>
<li><strong>内部节点 (Internal Node):</strong> 中间的判断节点。</li>
<li><strong>分支 (Branch):</strong> 代表一个判断的结果。</li>
<li><strong>叶节点 (Leaf Node):</strong> 最终的决策结果（类别标签，如“好瓜”或“坏瓜”）。</li>
</ul>
<p><strong>决策树如何构建？</strong></p>
<p>核心在于如何选择<strong>最优的特征</strong>在每个节点进行划分。目标是使得每次划分后，各个分支下的样本尽可能属于<strong>同一类别</strong>（即“纯度”尽可能高）。常用的衡量纯度的指标有：</p>
<ul>
<li><strong>信息熵 (Entropy):</strong> 度量系统的不确定性或混乱程度。熵越小，纯度越高。决策树倾向于选择能最大程度<strong>减少熵</strong>（即信息增益最大）的特征进行划分。</li>
<li><strong>基尼不纯度 (Gini Impurity):</strong> 另一种度量纯度的指标。基尼指数越小，纯度越高。CART (Classification and Regression Trees) 算法常用基尼指数。</li>
</ul>
<p>决策树会<strong>递归地</strong>选择最优特征进行分裂，直到满足停止条件（例如：节点样本已足够纯净、达到最大深度、节点样本数过少等）。</p>
</section>
<section id="使用-scikit-learn-实现" class="level3">
<h3 class="anchored" data-anchor-id="使用-scikit-learn-实现">1.2 使用 Scikit-learn 实现</h3>
<p>Scikit-learn 提供了 <code>DecisionTreeClassifier</code> 类。</p>
<div class="sourceCode" id="cb1"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.metrics <span class="im">import</span> accuracy_score, classification_report, confusion_matrix</span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> numpy <span class="im">as</span> np</span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 假设已有 X_train, X_test, y_train, y_test (来自上周) ---</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a><span class="co"># 如果没有，需要重新加载数据并划分</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a><span class="co"># 创建一些示例数据 (实际项目中应使用你的项目数据)</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>np.random.seed(<span class="dv">42</span>)</span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>X_example <span class="op">=</span> np.random.rand(<span class="dv">100</span>, <span class="dv">2</span>) <span class="op">*</span> <span class="dv">10</span> <span class="co"># 100个样本，2个特征</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>y_example <span class="op">=</span> (X_example[:, <span class="dv">0</span>] <span class="op">+</span> X_example[:, <span class="dv">1</span>] <span class="op">&gt;</span> <span class="dv">10</span>).astype(<span class="bu">int</span>)</span>
<span id="cb1-14"><a href="#cb1-14" aria-hidden="true" tabindex="-1"></a>X_train, X_test, y_train, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb1-15"><a href="#cb1-15" aria-hidden="true" tabindex="-1"></a>    X_example, y_example, test_size<span class="op">=</span><span class="fl">0.3</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_example</span>
<span id="cb1-16"><a href="#cb1-16" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb1-17"><a href="#cb1-17" aria-hidden="true" tabindex="-1"></a>feature_names_example <span class="op">=</span> [<span class="st">'Feature 1'</span>, <span class="st">'Feature 2'</span>] <span class="co"># 示例特征名</span></span>
<span id="cb1-18"><a href="#cb1-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-19"><a href="#cb1-19" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 训练决策树模型 ---</span></span>
<span id="cb1-20"><a href="#cb1-20" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 创建模型实例</span></span>
<span id="cb1-21"><a href="#cb1-21" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion: 'gini' 或 'entropy'，选择划分标准</span></span>
<span id="cb1-22"><a href="#cb1-22" aria-hidden="true" tabindex="-1"></a><span class="co"># max_depth: 树的最大深度，限制树的复杂度，防止过拟合</span></span>
<span id="cb1-23"><a href="#cb1-23" aria-hidden="true" tabindex="-1"></a><span class="co"># min_samples_split: 节点最少需要多少样本才能继续划分</span></span>
<span id="cb1-24"><a href="#cb1-24" aria-hidden="true" tabindex="-1"></a><span class="co"># min_samples_leaf: 叶节点最少需要包含多少样本</span></span>
<span id="cb1-25"><a href="#cb1-25" aria-hidden="true" tabindex="-1"></a><span class="co"># random_state: 保证结果可复现</span></span>
<span id="cb1-26"><a href="#cb1-26" aria-hidden="true" tabindex="-1"></a>dt_clf <span class="op">=</span> DecisionTreeClassifier(criterion<span class="op">=</span><span class="st">'gini'</span>, max_depth<span class="op">=</span><span class="dv">5</span>, random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb1-27"><a href="#cb1-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-28"><a href="#cb1-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 拟合模型</span></span>
<span id="cb1-29"><a href="#cb1-29" aria-hidden="true" tabindex="-1"></a>dt_clf.fit(X_train, y_train)</span>
<span id="cb1-30"><a href="#cb1-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-31"><a href="#cb1-31" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 预测与评估 ---</span></span>
<span id="cb1-32"><a href="#cb1-32" aria-hidden="true" tabindex="-1"></a>y_pred_dt <span class="op">=</span> dt_clf.predict(X_test)</span>
<span id="cb1-33"><a href="#cb1-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-34"><a href="#cb1-34" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- 决策树评估 ---"</span>)</span>
<span id="cb1-35"><a href="#cb1-35" aria-hidden="true" tabindex="-1"></a>accuracy_dt <span class="op">=</span> accuracy_score(y_test, y_pred_dt)</span>
<span id="cb1-36"><a href="#cb1-36" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"决策树准确率: </span><span class="sc">{</span>accuracy_dt<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb1-37"><a href="#cb1-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-38"><a href="#cb1-38" aria-hidden="true" tabindex="-1"></a>cm_dt <span class="op">=</span> confusion_matrix(y_test, y_pred_dt)</span>
<span id="cb1-39"><a href="#cb1-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"决策树混淆矩阵:</span><span class="ch">\n</span><span class="st">"</span>, cm_dt)</span>
<span id="cb1-40"><a href="#cb1-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-41"><a href="#cb1-41" aria-hidden="true" tabindex="-1"></a>report_dt <span class="op">=</span> classification_report(y_test, y_pred_dt, target_names<span class="op">=</span>[<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>])</span>
<span id="cb1-42"><a href="#cb1-42" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"决策树分类报告:</span><span class="ch">\n</span><span class="st">"</span>, report_dt)</span>
<span id="cb1-43"><a href="#cb1-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-44"><a href="#cb1-44" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 可视化决策树 ---</span></span>
<span id="cb1-45"><a href="#cb1-45" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">10</span>)) <span class="co"># 可以调整图像大小</span></span>
<span id="cb1-46"><a href="#cb1-46" aria-hidden="true" tabindex="-1"></a>plot_tree(dt_clf,</span>
<span id="cb1-47"><a href="#cb1-47" aria-hidden="true" tabindex="-1"></a>          filled<span class="op">=</span><span class="va">True</span>, <span class="co"># 用颜色填充节点以表示纯度</span></span>
<span id="cb1-48"><a href="#cb1-48" aria-hidden="true" tabindex="-1"></a>          rounded<span class="op">=</span><span class="va">True</span>, <span class="co"># 节点边框使用圆角</span></span>
<span id="cb1-49"><a href="#cb1-49" aria-hidden="true" tabindex="-1"></a>          class_names<span class="op">=</span>[<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>], <span class="co"># 显示类别名称</span></span>
<span id="cb1-50"><a href="#cb1-50" aria-hidden="true" tabindex="-1"></a>          feature_names<span class="op">=</span>feature_names_example) <span class="co"># 显示特征名称 (替换为你的实际特征名)</span></span>
<span id="cb1-51"><a href="#cb1-51" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show() # 在 Notebook 中取消注释以显示图像</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="优缺点" class="level3">
<h3 class="anchored" data-anchor-id="优缺点">1.3 优缺点</h3>
<ul>
<li><strong>优点:</strong>
<ul>
<li><strong>直观易懂:</strong> 模型结果容易解释和可视化。</li>
<li><strong>对数据预处理要求低:</strong> 通常不需要进行特征缩放。</li>
<li><strong>能处理数值和类别特征:</strong> (Scikit-learn 实现主要支持数值，类别需预处理)。</li>
<li><strong>能捕捉非线性关系。</strong></li>
</ul></li>
<li><strong>缺点:</strong>
<ul>
<li><strong>容易过拟合 (Overfitting):</strong> 决策树倾向于生成非常复杂的树来完美拟合训练数据，导致在测试数据上表现不佳。需要通过剪枝（限制树的生长，如 <code>max_depth</code>, <code>min_samples_leaf</code>）来缓解。</li>
<li><strong>对数据微小变化敏感:</strong> 数据微小的变动可能导致生成完全不同的树。</li>
<li><strong>倾向于偏向拥有更多取值的特征。</strong></li>
</ul></li>
</ul>
</section>
</section>
<section id="集成学习-ensemble-learning---随机森林" class="level2">
<h2 class="anchored" data-anchor-id="集成学习-ensemble-learning---随机森林">2. 集成学习 (Ensemble Learning) - 随机森林</h2>
<p>单个决策树容易过拟合，表现可能不稳定。<strong>集成学习</strong>通过构建并结合多个学习器（通常是同种类型的，如多个决策树）来获得比单个学习器更好的性能。所谓“三个臭皮匠，顶个诸葛亮”。</p>
<p><strong>随机森林 (Random Forest)</strong> 就是一种非常强大的、基于决策树的集成学习算法。</p>
<section id="bagging-思想" class="level3">
<h3 class="anchored" data-anchor-id="bagging-思想">2.1 Bagging 思想</h3>
<p>随机森林主要运用了 <strong>Bagging (Bootstrap Aggregating)</strong> 的思想：</p>
<ol type="1">
<li><strong>自助采样 (Bootstrap):</strong> 从原始训练数据集中<strong>有放回地</strong>随机抽取样本，构成一个新的训练子集。重复这个过程多次（例如 100 次），得到多个不同的训练子集。每个子集的大小通常与原始数据集相同，但由于是有放回抽样，某些样本可能出现多次，某些样本可能一次都不出现。</li>
<li><strong>独立训练:</strong> 在每个训练子集上独立地训练一个基学习器（在随机森林中就是决策树）。</li>
<li><strong>聚合 (Aggregating):</strong>
<ul>
<li>对于<strong>分类</strong>问题：让所有训练好的决策树进行投票，得票最多的类别作为最终预测结果。</li>
<li>对于<strong>回归</strong>问题：取所有决策树预测值的平均值作为最终预测结果。</li>
</ul></li>
</ol>
<p>Bagging 通过引入样本随机性，降低了模型的方差，提高了模型的稳定性和泛化能力。</p>
</section>
<section id="随机森林的随机" class="level3">
<h3 class="anchored" data-anchor-id="随机森林的随机">2.2 随机森林的“随机”</h3>
<p>随机森林在 Bagging 的基础上，进一步引入了<strong>特征随机性</strong>:</p>
<ul>
<li>在构建每棵决策树时，进行节点分裂选择特征时，<strong>不是从所有特征中选择最优特征，而是从随机抽取的一部分特征中选择最优特征</strong>。</li>
</ul>
<p>这种双重的随机性（样本随机 + 特征随机）使得森林中的每棵树都具有多样性，进一步减少了过拟合的风险，提高了模型的鲁棒性。</p>
</section>
<section id="使用-scikit-learn-实现-1" class="level3">
<h3 class="anchored" data-anchor-id="使用-scikit-learn-实现-1">2.3 使用 Scikit-learn 实现</h3>
<p>Scikit-learn 提供了 <code>RandomForestClassifier</code> 类。</p>
<div class="sourceCode" id="cb2"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> seaborn <span class="im">as</span> sns <span class="co"># 用于绘图</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-4"><a href="#cb2-4" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 训练随机森林模型 ---</span></span>
<span id="cb2-5"><a href="#cb2-5" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 创建模型实例</span></span>
<span id="cb2-6"><a href="#cb2-6" aria-hidden="true" tabindex="-1"></a><span class="co"># n_estimators: 森林中树的数量 (基学习器的数量)</span></span>
<span id="cb2-7"><a href="#cb2-7" aria-hidden="true" tabindex="-1"></a><span class="co"># criterion, max_depth, min_samples_split, min_samples_leaf: 与 DecisionTreeClassifier 类似，控制单棵树的生长</span></span>
<span id="cb2-8"><a href="#cb2-8" aria-hidden="true" tabindex="-1"></a><span class="co"># n_jobs: 并行运行的任务数 (-1 表示使用所有可用的 CPU 核心)</span></span>
<span id="cb2-9"><a href="#cb2-9" aria-hidden="true" tabindex="-1"></a><span class="co"># random_state: 保证结果可复现</span></span>
<span id="cb2-10"><a href="#cb2-10" aria-hidden="true" tabindex="-1"></a>rf_clf <span class="op">=</span> RandomForestClassifier(n_estimators<span class="op">=</span><span class="dv">100</span>, <span class="co"># 通常选择 100 或更多</span></span>
<span id="cb2-11"><a href="#cb2-11" aria-hidden="true" tabindex="-1"></a>                                criterion<span class="op">=</span><span class="st">'gini'</span>,</span>
<span id="cb2-12"><a href="#cb2-12" aria-hidden="true" tabindex="-1"></a>                                max_depth<span class="op">=</span><span class="dv">10</span>,     <span class="co"># 可以适当增加深度</span></span>
<span id="cb2-13"><a href="#cb2-13" aria-hidden="true" tabindex="-1"></a>                                n_jobs<span class="op">=-</span><span class="dv">1</span>,</span>
<span id="cb2-14"><a href="#cb2-14" aria-hidden="true" tabindex="-1"></a>                                random_state<span class="op">=</span><span class="dv">42</span>)</span>
<span id="cb2-15"><a href="#cb2-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-16"><a href="#cb2-16" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 拟合模型</span></span>
<span id="cb2-17"><a href="#cb2-17" aria-hidden="true" tabindex="-1"></a>rf_clf.fit(X_train, y_train)</span>
<span id="cb2-18"><a href="#cb2-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-19"><a href="#cb2-19" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 预测与评估 ---</span></span>
<span id="cb2-20"><a href="#cb2-20" aria-hidden="true" tabindex="-1"></a>y_pred_rf <span class="op">=</span> rf_clf.predict(X_test)</span>
<span id="cb2-21"><a href="#cb2-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-22"><a href="#cb2-22" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- 随机森林评估 ---"</span>)</span>
<span id="cb2-23"><a href="#cb2-23" aria-hidden="true" tabindex="-1"></a>accuracy_rf <span class="op">=</span> accuracy_score(y_test, y_pred_rf)</span>
<span id="cb2-24"><a href="#cb2-24" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"随机森林准确率: </span><span class="sc">{</span>accuracy_rf<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb2-25"><a href="#cb2-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-26"><a href="#cb2-26" aria-hidden="true" tabindex="-1"></a>cm_rf <span class="op">=</span> confusion_matrix(y_test, y_pred_rf)</span>
<span id="cb2-27"><a href="#cb2-27" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"随机森林混淆矩阵:</span><span class="ch">\n</span><span class="st">"</span>, cm_rf)</span>
<span id="cb2-28"><a href="#cb2-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-29"><a href="#cb2-29" aria-hidden="true" tabindex="-1"></a>report_rf <span class="op">=</span> classification_report(y_test, y_pred_rf, target_names<span class="op">=</span>[<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>])</span>
<span id="cb2-30"><a href="#cb2-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"随机森林分类报告:</span><span class="ch">\n</span><span class="st">"</span>, report_rf)</span>
<span id="cb2-31"><a href="#cb2-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-32"><a href="#cb2-32" aria-hidden="true" tabindex="-1"></a><span class="co"># (可选) 查看特征重要性</span></span>
<span id="cb2-33"><a href="#cb2-33" aria-hidden="true" tabindex="-1"></a>importances <span class="op">=</span> rf_clf.feature_importances_</span>
<span id="cb2-34"><a href="#cb2-34" aria-hidden="true" tabindex="-1"></a><span class="co"># 将重要性与特征名对应起来</span></span>
<span id="cb2-35"><a href="#cb2-35" aria-hidden="true" tabindex="-1"></a><span class="co"># feature_names = ['Feature 1', 'Feature 2'] # 替换为你的实际特征名</span></span>
<span id="cb2-36"><a href="#cb2-36" aria-hidden="true" tabindex="-1"></a>feature_importance_df <span class="op">=</span> pd.DataFrame({<span class="st">'Feature'</span>: feature_names_example, <span class="st">'Importance'</span>: importances})</span>
<span id="cb2-37"><a href="#cb2-37" aria-hidden="true" tabindex="-1"></a>feature_importance_df <span class="op">=</span> feature_importance_df.sort_values(by<span class="op">=</span><span class="st">'Importance'</span>, ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb2-38"><a href="#cb2-38" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">特征重要性:</span><span class="ch">\n</span><span class="st">"</span>, feature_importance_df)</span>
<span id="cb2-39"><a href="#cb2-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb2-40"><a href="#cb2-40" aria-hidden="true" tabindex="-1"></a><span class="co"># 可视化特征重要性</span></span>
<span id="cb2-41"><a href="#cb2-41" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">10</span>, <span class="dv">6</span>))</span>
<span id="cb2-42"><a href="#cb2-42" aria-hidden="true" tabindex="-1"></a>sns.barplot(x<span class="op">=</span><span class="st">'Importance'</span>, y<span class="op">=</span><span class="st">'Feature'</span>, data<span class="op">=</span>feature_importance_df)</span>
<span id="cb2-43"><a href="#cb2-43" aria-hidden="true" tabindex="-1"></a>plt.title(<span class="st">'Feature Importance (Random Forest)'</span>)</span>
<span id="cb2-44"><a href="#cb2-44" aria-hidden="true" tabindex="-1"></a><span class="co"># plt.show()</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</section>
<section id="随机森林优点" class="level3">
<h3 class="anchored" data-anchor-id="随机森林优点">2.4 随机森林优点</h3>
<ul>
<li><strong>性能强大:</strong> 通常比单个决策树表现更好，是目前最常用的机器学习算法之一。</li>
<li><strong>抗过拟合能力强:</strong> 双重随机性使其不容易过拟合。</li>
<li><strong>能处理高维数据:</strong> 特征随机性使其在高维数据上表现良好。</li>
<li><strong>能评估特征重要性:</strong> 可以了解哪些特征对预测贡献更大。</li>
<li><strong>对数据预处理要求相对较低:</strong> 通常不需要特征缩放。</li>
<li><strong>易于并行化:</strong> 每棵树可以独立训练。</li>
</ul>
</section>
</section>
<section id="模型优化交叉验证与网格搜索" class="level2">
<h2 class="anchored" data-anchor-id="模型优化交叉验证与网格搜索">3. 模型优化：交叉验证与网格搜索</h2>
<p>我们之前训练模型时，只将数据划分了一次训练集和测试集。这种方式得到的模型评估结果可能具有偶然性，受单次划分的影响较大。同时，像 SVM 的 <code>C</code>, <code>gamma</code> 或随机森林的 <code>n_estimators</code>, <code>max_depth</code> 等<strong>超参数 (Hyperparameters)</strong> 的选择也会显著影响模型性能，手动尝试不同的组合效率低下。</p>
<section id="交叉验证-cross-validation-cv" class="level3">
<h3 class="anchored" data-anchor-id="交叉验证-cross-validation-cv">3.1 交叉验证 (Cross-Validation, CV)</h3>
<p>交叉验证是一种更可靠的模型评估方法。它将训练数据进一步划分为多个<strong>折 (Fold)</strong>，多次训练和评估模型，最后取平均结果。最常用的是 <strong>K 折交叉验证 (K-Fold Cross-Validation)</strong>:</p>
<ol type="1">
<li>将<strong>训练集</strong>随机划分为 K 个大小相似的互斥子集（折）。</li>
<li>进行 K 次迭代：
<ul>
<li>在第 i 次迭代中，将第 i 个折作为<strong>验证集 (Validation Set)</strong>，其余 K-1 个折合并作为<strong>训练集</strong>。</li>
<li>在该训练集上训练模型。</li>
<li>在验证集上评估模型性能。</li>
</ul></li>
<li>将 K 次迭代得到的评估指标（如准确率、F1 分数）取平均值，作为最终的模型性能评估结果。</li>
</ol>
<p><strong>优点:</strong></p>
<ul>
<li>更充分地利用了数据。</li>
<li>评估结果更稳定、更可靠，减少了单次划分带来的偶然性。</li>
</ul>
<p>Scikit-learn 提供了 <code>cross_val_score</code> 函数来方便地执行交叉验证。</p>
<div class="sourceCode" id="cb3"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> cross_val_score</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 使用 K 折交叉验证评估随机森林模型 (在整个训练集 X_train 上)</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a><span class="co"># cv=5 表示 5 折交叉验证</span></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span class="co"># scoring='accuracy' 指定评估指标，也可以是 'f1', 'precision', 'recall', 'roc_auc' 等</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a><span class="co"># 注意：这里我们用之前创建的 rf_clf 实例进行评估</span></span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>scores <span class="op">=</span> cross_val_score(rf_clf, X_train, y_train, cv<span class="op">=</span><span class="dv">5</span>, scoring<span class="op">=</span><span class="st">'accuracy'</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>)</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"</span><span class="ch">\n</span><span class="ss">随机森林 5 折交叉验证准确率: </span><span class="sc">{</span>scores<span class="sc">}</span><span class="ss">"</span>)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"平均准确率: </span><span class="sc">{</span>scores<span class="sc">.</span>mean()<span class="sc">:.4f}</span><span class="ss"> (+/- </span><span class="sc">{</span>scores<span class="sc">.</span>std() <span class="op">*</span> <span class="dv">2</span><span class="sc">:.4f}</span><span class="ss">)"</span>) <span class="co"># 通常报告均值和两倍标准差范围</span></span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-note callout-titled" title="Stratified K-Fold">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Stratified K-Fold
</div>
</div>
<div class="callout-body-container callout-body">
<p>对于分类问题，尤其是不平衡数据，推荐使用 <strong>Stratified K-Fold</strong>。它在划分折时会保持每个折中类别比例与原始数据集一致。<code>cross_val_score</code> 在处理分类问题时通常默认使用 Stratified K-Fold。</p>
</div>
</div>
</section>
<section id="网格搜索-grid-search" class="level3">
<h3 class="anchored" data-anchor-id="网格搜索-grid-search">3.2 网格搜索 (Grid Search)</h3>
<p>网格搜索是一种自动化的<strong>超参数调优 (Hyperparameter Tuning)</strong> 方法。它会尝试你指定的所有超参数组合，并通过交叉验证来评估每种组合的性能，最终找到最优的超参数组合。</p>
<ol type="1">
<li><strong>定义参数网格:</strong> 指定你想要尝试的超参数及其候选值。</li>
<li><strong>遍历组合:</strong> 网格搜索会尝试参数网格中所有可能的超参数组合。</li>
<li><strong>交叉验证评估:</strong> 对于每一种超参数组合，使用交叉验证来评估模型性能。</li>
<li><strong>选择最优参数:</strong> 选择在交叉验证中表现最好的那组超参数。</li>
<li><strong>重新训练:</strong> 使用找到的最优超参数，在<strong>整个训练集</strong>上重新训练最终的模型。</li>
</ol>
<p>Scikit-learn 提供了 <code>GridSearchCV</code> 类。</p>
<div class="sourceCode" id="cb4"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> GridSearchCV</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span class="co"># 1. 定义参数网格 (以 RandomForest 为例)</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>param_grid <span class="op">=</span> {</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>    <span class="st">'n_estimators'</span>: [<span class="dv">50</span>, <span class="dv">100</span>, <span class="dv">200</span>],       <span class="co"># 尝试不同的树数量</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>    <span class="st">'max_depth'</span>: [<span class="dv">5</span>, <span class="dv">10</span>, <span class="dv">15</span>, <span class="va">None</span>],     <span class="co"># 尝试不同的最大深度 (None 表示不限制)</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_split'</span>: [<span class="dv">2</span>, <span class="dv">5</span>, <span class="dv">10</span>],    <span class="co"># 尝试不同的节点最小分裂样本数</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    <span class="st">'min_samples_leaf'</span>: [<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>]       <span class="co"># 尝试不同的叶节点最小样本数</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    <span class="co"># 'criterion': ['gini', 'entropy'] # 也可以加入划分标准</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span class="co"># 2. 创建 GridSearchCV 实例</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a><span class="co"># estimator: 要调优的模型实例</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a><span class="co"># param_grid: 参数网格</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a><span class="co"># cv: 交叉验证折数</span></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span class="co"># scoring: 评估指标</span></span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a><span class="co"># n_jobs: 并行任务数</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a><span class="co"># verbose: 控制运行时输出信息的详细程度 (值越大越详细)</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>grid_search <span class="op">=</span> GridSearchCV(estimator<span class="op">=</span>RandomForestClassifier(random_state<span class="op">=</span><span class="dv">42</span>, n_jobs<span class="op">=-</span><span class="dv">1</span>),</span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>                           param_grid<span class="op">=</span>param_grid,</span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>                           cv<span class="op">=</span><span class="dv">3</span>, <span class="co"># 使用 3 折 CV 加快速度 (实际可设为 5 或 10)</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>                           scoring<span class="op">=</span><span class="st">'accuracy'</span>,</span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>                           verbose<span class="op">=</span><span class="dv">1</span>)</span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a><span class="co"># 3. 在训练集上执行网格搜索 (这可能需要一些时间)</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>grid_search.fit(X_train, y_train)</span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a><span class="co"># 4. 查看最优参数和最优分数</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- 网格搜索结果 ---"</span>)</span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"找到的最优超参数:"</span>, grid_search.best_params_)</span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"最优交叉验证准确率: </span><span class="sc">{</span>grid_search<span class="sc">.</span>best_score_<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a><span class="co"># 5. 获取最优模型</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>best_rf_clf <span class="op">=</span> grid_search.best_estimator_</span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a><span class="co"># --- 使用最优模型进行预测和评估 ---</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>y_pred_best_rf <span class="op">=</span> best_rf_clf.predict(X_test)</span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"</span><span class="ch">\n</span><span class="st">--- 最优随机森林评估 ---"</span>)</span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>accuracy_best_rf <span class="op">=</span> accuracy_score(y_test, y_pred_best_rf)</span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="ss">f"最优随机森林在测试集上的准确率: </span><span class="sc">{</span>accuracy_best_rf<span class="sc">:.4f}</span><span class="ss">"</span>)</span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>report_best_rf <span class="op">=</span> classification_report(y_test, y_pred_best_rf, target_names<span class="op">=</span>[<span class="st">'Class 0'</span>, <span class="st">'Class 1'</span>])</span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a><span class="bu">print</span>(<span class="st">"最优随机森林分类报告:</span><span class="ch">\n</span><span class="st">"</span>, report_best_rf)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="callout callout-style-default callout-tip callout-titled" title="AI 辅助理解 CV 与 GridSearch">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
AI 辅助理解 CV 与 GridSearch
</div>
</div>
<div class="callout-body-container callout-body">
<ul>
<li>“解释 K 折交叉验证的步骤及其相比简单划分训练/测试集的优势。”</li>
<li>“什么是超参数？它和模型参数有什么区别？”</li>
<li>“GridSearchCV 是如何工作的？它的 <code>cv</code> 和 <code>scoring</code> 参数分别是什么意思？”</li>
<li>“除了 GridSearchCV，还有哪些常用的超参数调优方法？（例如 RandomizedSearchCV）”</li>
<li>“帮我为 SVM 的 <code>C</code> 和 <code>gamma</code> 参数写一个 <code>param_grid</code> 用于 GridSearchCV。”</li>
</ul>
</div>
</div>
</section>
</section>
<section id="小组项目一模型优化与最终报告" class="level2">
<h2 class="anchored" data-anchor-id="小组项目一模型优化与最终报告">4. 小组项目一：模型优化与最终报告</h2>
<p>本周是项目一的最后阶段！你需要使用随机森林优化你的分类模型，并利用网格搜索寻找最佳超参数。</p>
<ul>
<li><strong>任务:</strong>
<ol type="1">
<li><strong>训练随机森林:</strong> 在你的预处理数据上训练一个 <code>RandomForestClassifier</code> 模型（可以使用默认参数或基于决策树表现初步选择参数）。</li>
<li><strong>评估随机森林:</strong> 使用交叉验证 (<code>cross_val_score</code>) 评估其性能，并与之前的 LR 和 SVM 模型进行比较。</li>
<li><strong>定义参数网格:</strong> 为 <code>RandomForestClassifier</code> 定义一个合适的 <code>param_grid</code>，包含你认为重要的超参数（如 <code>n_estimators</code>, <code>max_depth</code>, <code>min_samples_split</code>, <code>min_samples_leaf</code>）及其候选值。</li>
<li><strong>执行网格搜索:</strong> 使用 <code>GridSearchCV</code> 寻找随机森林的最佳超参数组合（使用交叉验证，例如 <code>cv=5</code>）。</li>
<li><strong>评估最优模型:</strong> 使用网格搜索找到的最佳模型 (<code>best_estimator_</code>) 对<strong>测试集</strong>进行预测，并计算最终的评估指标（准确率、混淆矩阵、分类报告、ROC AUC）。记得与之前的模型结果进行对比。</li>
<li><strong>对比与分析:</strong>
<ul>
<li>比较调优后的随机森林与之前所有模型（LR, SVM, 初始 RF）的性能。调优是否带来了提升？哪个模型最终表现最好？</li>
<li>分析最优随机森林的特征重要性 (<code>feature_importances_</code>)，哪些特征对预测用户行为最重要？这符合你的预期吗？（需要将特征重要性与你的实际特征名对应起来）。</li>
<li>总结项目一的整个流程、遇到的挑战、解决方法以及最终模型的表现和业务解读（例如，根据模型结果，可以为电商平台提供哪些建议？）。</li>
</ul></li>
</ol></li>
<li><strong>提交:</strong>
<ul>
<li>最终的 Jupyter Notebook (<code>.ipynb</code>)，包含所有步骤的代码、结果和分析。确保代码清晰、注释充分，结果可视化。</li>
<li>一份简洁的项目报告 (<code>.md</code> 或 <code>.pdf</code> 格式)，总结项目目标、数据描述、预处理步骤、模型选择与调优过程、最终模型评估结果、特征重要性分析、结论与业务建议。</li>
</ul></li>
<li><strong>DDL:</strong> 第五周第一次课前。</li>
</ul>
</section>
<section id="本周总结" class="level2">
<h2 class="anchored" data-anchor-id="本周总结">5. 本周总结</h2>
<p>本周我们学习了决策树和强大的集成算法随机森林。我们理解了 Bagging 和特征随机性的原理，并掌握了如何在 Scikit-learn 中使用它们。我们还学习了通过交叉验证进行更可靠的模型评估，以及利用网格搜索自动化超参数调优的关键技术。最后，我们将这些优化方法应用到了项目一中。</p>
<p><strong>下周我们将转向另一类重要的监督学习问题——回归，并学习线性回归及其变种！</strong></p>


</section>

</main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    // For code content inside modals, clipBoardJS needs to be initialized with a container option
    // TODO: Check when it could be a function (https://github.com/zenorocha/clipboard.js/issues/860)
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      // TODO in 1.5, we should make sure this works without a callout special case
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
<nav class="page-navigation">
  <div class="nav-page nav-page-previous">
      <a href="./week3_lecture.html" class="pagination-link" aria-label="第三周：分类算法初探 - 逻辑回归与支持向量机">
        <i class="bi bi-arrow-left-short"></i> <span class="nav-page-text"><span class="chapter-title">第三周：分类算法初探 - 逻辑回归与支持向量机</span></span>
      </a>          
  </div>
  <div class="nav-page nav-page-next">
      <a href="./week5_lecture.html" class="pagination-link" aria-label="第五周：回归算法启程 - 线性回归与多项式回归">
        <span class="nav-page-text"><span class="chapter-title">第五周：回归算法启程 - 线性回归与多项式回归</span></span> <i class="bi bi-arrow-right-short"></i>
      </a>
  </div>
</nav>
</div> <!-- /content -->




</body></html>